"""
Hybrid Entry Evaluator for Paper Trading (Issue #494, #510).

Uses rule-based signals for entries, replacing PPO-based entry prediction.
This implements the hybrid architecture where entries are rule-based and
exits are RL-managed.

Key Features:
- D1 SMA20/SMA50 crossover detection (proven 59.8% WR) - default
- H4 timeframe support with EMA12/EMA26 crossover and ATR breakout (Issue #510)
- Configurable signal types per symbol via signal_config
- Crossover-level signal locking (one trade per crossover event)
- Database-based data fetching (production-ready)
- Compatible with existing paper trading infrastructure

Architecture:
    Indicators (DB) -> Signal Detection -> Entry Signal
                                      -> Signal Locking

Supported Timeframes:
    - D1: SMA20/SMA50 crossover (default)
    - H4: EMA12/EMA26 crossover, ATR breakout (via signal_config)
"""

import logging
import time
from dataclasses import dataclass
from datetime import datetime, timezone
from decimal import Decimal
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

# Issue #561: Import dynamic signal parser
from src.paper_trading.signal_parser import SignalParser

logger = logging.getLogger(__name__)


# =============================================================================
# Constants
# =============================================================================

# Default symbols for hybrid trading
DEFAULT_SYMBOLS: List[str] = [
    "EURUSD",
    "GBPUSD",
    "USDJPY",
    "EURJPY",
    "XAGUSD",
    "USDCAD",
    "EURCAD",
]

# D1 indicator table mapping per symbol
D1_INDICATOR_TABLES: Dict[str, str] = {
    "EURUSD": "technical_indicators",
    "GBPUSD": "technical_indicator_gbpusd",
    "USDJPY": "technical_indicator_usdjpy",
    "EURJPY": "technical_indicator_eurjpy",
    "XAGUSD": "technical_indicator_xagusd",
    "USDCAD": "technical_indicator_usdcad",
    "EURCAD": "technical_indicator_eurcad",
}

# M30 indicator table mapping per symbol (for H4 aggregation)
M30_INDICATOR_TABLES: Dict[str, str] = {
    "EURUSD": "technical_indicator_eurusd",
    "GBPUSD": "technical_indicator_gbpusd",
    "USDJPY": "technical_indicator_usdjpy",
    "EURJPY": "technical_indicator_eurjpy",
    "XAGUSD": "technical_indicator_xagusd",
    "USDCAD": "technical_indicator_usdcad",
    "EURCAD": "technical_indicator_eurcad",
    "EURGBP": "technical_indicator_eurgbp",
    "USDCHF": "technical_indicator_usdchf",
}

# Symbol to database name mapping
SYMBOL_DB_NAMES: Dict[str, str] = {
    "EURUSD": "eurusd",
    "GBPUSD": "gbpusd",
    "USDJPY": "usdjpy",
    "EURJPY": "eurjpy",
    "XAGUSD": "xagusd",
    "USDCAD": "usdcad",
    "EURCAD": "eurcad",
}

# Crossover detection lookback (bars)
CROSS_LOOKBACK: int = 5

# ATR breakout threshold multiplier
ATR_BREAKOUT_THRESHOLD: float = 2.0

# RSI thresholds for extreme conditions
RSI_OVERSOLD_THRESHOLD: float = 25.0
RSI_VERY_OVERSOLD_THRESHOLD: float = 20.0
RSI_OVERBOUGHT_THRESHOLD: float = 75.0

# Bollinger Bands parameters
BB_PERIOD: int = 20
BB_STD: float = 2.0
BB_SQUEEZE_THRESHOLD: float = 0.02  # Width threshold for squeeze detection

# Signal types
SIGNAL_LONG = "LONG"
SIGNAL_SHORT = "SHORT"

# Supported timeframes for multi-timeframe data fetching (Issue #569)
SUPPORTED_TIMEFRAMES: List[str] = [
    "M30",  # 30 minutes
    "H1",   # 1 hour
    "H2",   # 2 hours
    "H3",   # 3 hours
    "H4",   # 4 hours
    "H6",   # 6 hours
    "H8",   # 8 hours
    "H12",  # 12 hours
    "D1",   # Daily
]

# Cache timeouts per timeframe (in seconds) - shorter timeframes expire faster
TIMEFRAME_CACHE_TIMEOUT: Dict[str, int] = {
    "M30": 900,    # 15 minutes
    "H1": 1800,    # 30 minutes
    "H2": 1800,    # 30 minutes
    "H3": 1800,    # 30 minutes
    "H4": 1800,    # 30 minutes
    "H6": 2700,    # 45 minutes
    "H8": 2700,    # 45 minutes
    "H12": 3600,   # 1 hour
    "D1": 3600,    # 1 hour
}

# M30 bars per timeframe (for aggregation if direct query not available)
M30_BARS_PER_TIMEFRAME: Dict[str, int] = {
    "M30": 1,
    "H1": 2,
    "H2": 4,
    "H3": 6,
    "H4": 8,
    "H6": 12,
    "H8": 16,
    "H12": 24,
    "D1": 48,  # Approximate for daily
}


# =============================================================================
# Data Classes
# =============================================================================


@dataclass
class HybridEntrySignal:
    """Entry signal generated by hybrid D1 crossover detection.

    Attributes:
        symbol: Trading symbol (e.g., "EURUSD")
        direction: Trade direction ("LONG" or "SHORT")
        confidence: Signal strength (0.0 to 1.0)
        timestamp: UTC timestamp of signal generation
        candle_time: D1 candle timestamp that generated signal
        crossover_origin: D1 bar where crossover actually occurred (for locking)
        signal_source: Description of signal source
        timeframe: Timeframe of the signal (M30, H1, H2, etc.)
    """

    symbol: str
    direction: str
    confidence: float
    timestamp: datetime
    candle_time: datetime
    crossover_origin: datetime
    signal_source: str = "D1_SMA_CROSSOVER"
    timeframe: str = "D1"

    def __post_init__(self) -> None:
        """Validate entry signal fields."""
        if self.direction not in ["LONG", "SHORT"]:
            raise ValueError(f"Invalid direction: {self.direction}")
        if not 0.0 <= self.confidence <= 1.0:
            raise ValueError(f"Confidence must be 0.0-1.0, got {self.confidence}")


# =============================================================================
# Hybrid Entry Evaluator
# =============================================================================


class HybridEntryEvaluator:
    """Hybrid entry evaluator using rule-based signals.

    This evaluator implements the entry side of the hybrid architecture:
    - Supports D1 (default) and H4 timeframes
    - D1: SMA20/SMA50 crossover detection
    - H4: EMA12/EMA26 crossover, ATR breakout (via signal_config)
    - Applies crossover-level signal locking (one trade per crossover)
    - Returns entry signals compatible with paper trading infrastructure

    Usage:
        # D1 mode (default, backward compatible)
        evaluator = HybridEntryEvaluator(
            symbols=["EURUSD", "GBPUSD"],
            db_manager=db_manager,
        )

        # H4 mode with custom signals
        evaluator = HybridEntryEvaluator(
            symbols=["EURUSD", "USDJPY"],
            db_manager=db_manager,
            timeframe="H4",
            signal_config={
                "EURUSD": {"signal": "EMA12_cross_EMA26", "direction": "short"},
                "USDJPY": {"signal": "ATR_breakout", "direction": "short"},
            },
        )

        signal = evaluator.evaluate_entry("EURUSD")
        if signal:
            print(f"Entry: {signal.direction} at {signal.timestamp}")
    """

    def __init__(
        self,
        symbols: Optional[List[str]] = None,
        db_manager: Any = None,
        cross_lookback: int = CROSS_LOOKBACK,
        timeframe: str = "D1",
        signal_config: Optional[Dict[str, Any]] = None,
        lifecycle_client: Any = None,
    ) -> None:
        """Initialize HybridEntryEvaluator.

        Args:
            symbols: List of symbols to evaluate
            db_manager: Database manager for fetching indicators
            cross_lookback: Bars to look back for crossover detection
            timeframe: Timeframe to use ("D1" or "H4")
            signal_config: Per-symbol signal configuration for H4 mode
                Supports both single signal (legacy) and multiple signals (new):
                Legacy: {"EURUSD": {"signal": "EMA12_cross_EMA26", "direction": "short"}}
                New:    {"EURUSD": [{"signal": "signal1", "direction": "long"}, ...]}
            lifecycle_client: Optional LifecycleClient for filtering non-tradeable signals.
                If None, all signals are allowed (backward compatible).
        """
        self.symbols = symbols if symbols is not None else DEFAULT_SYMBOLS
        self.db = db_manager
        self.cross_lookback = cross_lookback
        self.timeframe = timeframe.upper()
        self.signal_config = signal_config if signal_config is not None else {}
        self._lifecycle_client = lifecycle_client

        # Signal locking: track last traded crossover per symbol+signal
        # Key format: "SYMBOL:signal_name" to allow per-signal locking
        self._last_traded_crossover: Dict[str, datetime] = {}

        # Data cache per symbol (for both D1 and H4)
        self._d1_cache: Dict[str, pd.DataFrame] = {}
        self._h4_cache: Dict[str, pd.DataFrame] = {}
        self._cache_timestamp: Dict[str, datetime] = {}

        # Issue #569: Generic timeframe cache for M30, H1, H2, H3, H6, H8, H12
        # Key format: "SYMBOL_TIMEFRAME" (e.g., "GBPUSD_H1")
        self._timeframe_cache: Dict[str, pd.DataFrame] = {}

        # Issue #585: Rate-limited signal health summary counters
        self._eval_cycle_count: int = 0
        self._total_triggered: int = 0
        self._total_locked: int = 0
        self._last_info_summary_time: float = time.monotonic()
        self._info_summary_cycle_interval: int = 100  # every N cycles
        self._info_summary_time_interval: float = 600.0  # every 10 minutes

        # Issue #561: Dynamic signal parser - eliminates manual handlers
        try:
            self._signal_parser = SignalParser()
            logger.info(
                f"SignalParser loaded: {len(self._signal_parser.definitions)} dynamic signals available"
            )
        except Exception as e:
            logger.warning(f"SignalParser not available, using hardcoded handlers: {e}")
            self._signal_parser = None

        logger.info(
            f"HybridEntryEvaluator initialized: symbols={self.symbols}, "
            f"timeframe={self.timeframe}, cross_lookback={cross_lookback}"
        )

    def evaluate_entry(self, symbol: str) -> Optional[HybridEntrySignal]:
        """Evaluate ALL entry signals for a symbol.

        Issue #541: Now evaluates ALL configured signals, not just the first.
        Issue #569 Stream C: Each signal fetches data for its OWN timeframe.

        For each configured signal, this method:
        1. Gets the signal's timeframe from config (or falls back to evaluator default)
        2. Fetches data for THAT specific timeframe
        3. Evaluates the signal against its correct timeframe data

        Applies per-signal locking to prevent duplicate trades.

        Args:
            symbol: Trading symbol (e.g., "EURUSD")

        Returns:
            HybridEntrySignal if any signal triggers, None otherwise
        """
        symbol = symbol.upper()

        if symbol not in self.symbols:
            logger.warning(f"Symbol {symbol} not in configured symbols")
            return None

        # Get signal configs for this symbol (handle both legacy and new format)
        symbol_config = self.signal_config.get(symbol, {})

        # Convert to list format for uniform handling
        if isinstance(symbol_config, dict):
            # Legacy single signal format
            signal_configs = [symbol_config] if symbol_config else []
        elif isinstance(symbol_config, list):
            # New multi-signal format
            signal_configs = symbol_config
        else:
            signal_configs = []

        # D1 default fallback if no signals configured
        if not signal_configs:
            # Use evaluator's default timeframe for D1 fallback
            data = self._fetch_timeframe_data(symbol)
            if data is None or len(data) < self.cross_lookback + 1:
                logger.debug(f"Insufficient {self.timeframe} data for {symbol}")
                return None
            signal, crossover_origin = self._detect_crossover(data)
            if signal is None:
                return None
            if self._is_crossover_locked(symbol, crossover_origin):
                logger.debug(f"Signal locked for {symbol}: crossover at {crossover_origin}")
                return None
            return self._create_entry_signal(symbol, signal, data, crossover_origin, "D1_SMA_CROSSOVER", self.timeframe)

        # Multi-signal mode: Evaluate ALL configured signals with THEIR timeframes
        # Issue #569 Stream C: Each signal fetches data for its own timeframe
        # Issue #585: Track per-cycle counters for diagnostic summary
        signals_checked = 0
        signals_triggered = 0
        signals_locked = 0
        signals_no_data = 0
        signals_no_match = 0
        triggered_result = None

        for sig_config in signal_configs:
            signal_type = sig_config.get("signal", "")
            expected_direction = sig_config.get("direction", "long").upper()
            # Issue #569: Get per-signal timeframe, fall back to evaluator default
            signal_timeframe = sig_config.get("timeframe", self.timeframe)
            signals_checked += 1

            # Fetch data for THIS signal's timeframe
            data = self._fetch_timeframe_data(symbol, signal_timeframe)
            if data is None or len(data) < self.cross_lookback + 1:
                signals_no_data += 1
                logger.debug(
                    f"Insufficient {signal_timeframe} data for {symbol}:{signal_type}"
                )
                continue  # Skip this signal, try next

            # Detect this specific signal
            signal, crossover_origin = self._detect_signal_for_config(data, signal_type, expected_direction)

            if signal is None:
                signals_no_match += 1
                continue  # This signal didn't trigger, try next

            # Check per-signal locking (key: "SYMBOL:signal_type")
            lock_key = f"{symbol}:{signal_type}"
            if self._is_signal_locked(lock_key, crossover_origin):
                signals_locked += 1
                logger.debug(f"Signal locked for {lock_key}: crossover at {crossover_origin}")
                continue  # This signal is locked, try next

            # Lifecycle check: block entries for non-tradeable signals
            if self._lifecycle_client is not None:
                signal_id = f"{symbol.lower()}_{expected_direction.lower()}_{signal_type}_{signal_timeframe}"
                try:
                    if not self._lifecycle_client.is_signal_tradeable(signal_id):
                        logger.info(
                            f"Signal {signal_type} blocked: lifecycle state non-tradeable "
                            f"(signal_id={signal_id})"
                        )
                        continue
                except Exception as e:
                    # Fail-open: allow signal if lifecycle check errors
                    logger.warning(
                        f"Lifecycle check failed for {signal_id}, allowing signal (fail-open): {e}"
                    )

            # Signal triggered! Create and return entry signal
            signals_triggered += 1
            logger.info(
                f"Signal triggered: {symbol} {signal_type} [{signal_timeframe}] -> {signal}"
            )
            triggered_result = self._create_entry_signal(symbol, signal, data, crossover_origin, signal_type, signal_timeframe)
            break  # Return first triggered signal after logging summary

        # Issue #585: Per-cycle summary log
        logger.debug(
            f"Signal evaluation summary for {symbol}: "
            f"checked={signals_checked}, triggered={signals_triggered}, "
            f"locked={signals_locked}, no_data={signals_no_data}, "
            f"no_match={signals_no_match}"
        )

        # Issue #585: Update aggregate counters for rate-limited INFO summary
        self._eval_cycle_count += 1
        self._total_triggered += signals_triggered
        self._total_locked += signals_locked
        self._emit_rate_limited_info_summary(symbol)

        return triggered_result

    def evaluate_entries(self, symbol: str) -> List[HybridEntrySignal]:
        """Evaluate ALL entry signals for a symbol, returning all that trigger.

        Unlike evaluate_entry() which returns only the first triggered signal,
        this method collects ALL triggered signals for batch processing.
        This enables fair volume allocation across simultaneously triggered signals.

        Args:
            symbol: Trading symbol (e.g., "EURUSD")

        Returns:
            List of HybridEntrySignal for all triggered signals (may be empty)
        """
        symbol = symbol.upper()

        if symbol not in self.symbols:
            logger.warning(f"Symbol {symbol} not in configured symbols")
            return []

        # Get signal configs for this symbol (handle both legacy and new format)
        symbol_config = self.signal_config.get(symbol, {})

        # Convert to list format for uniform handling
        if isinstance(symbol_config, dict):
            signal_configs = [symbol_config] if symbol_config else []
        elif isinstance(symbol_config, list):
            signal_configs = symbol_config
        else:
            signal_configs = []

        # D1 default fallback if no signals configured
        if not signal_configs:
            data = self._fetch_timeframe_data(symbol)
            if data is None or len(data) < self.cross_lookback + 1:
                logger.debug(f"Insufficient {self.timeframe} data for {symbol}")
                return []
            signal, crossover_origin = self._detect_crossover(data)
            if signal is None:
                return []
            if self._is_crossover_locked(symbol, crossover_origin):
                logger.debug(f"Signal locked for {symbol}: crossover at {crossover_origin}")
                return []
            return [self._create_entry_signal(symbol, signal, data, crossover_origin, "D1_SMA_CROSSOVER", self.timeframe)]

        # Multi-signal mode: Evaluate ALL configured signals, collect all triggered
        signals_checked = 0
        signals_triggered = 0
        signals_locked = 0
        signals_no_data = 0
        signals_no_match = 0
        triggered_results: List[HybridEntrySignal] = []

        for sig_config in signal_configs:
            signal_type = sig_config.get("signal", "")
            expected_direction = sig_config.get("direction", "long").upper()
            signal_timeframe = sig_config.get("timeframe", self.timeframe)
            signals_checked += 1

            data = self._fetch_timeframe_data(symbol, signal_timeframe)
            if data is None or len(data) < self.cross_lookback + 1:
                signals_no_data += 1
                logger.debug(
                    f"Insufficient {signal_timeframe} data for {symbol}:{signal_type}"
                )
                continue

            signal, crossover_origin = self._detect_signal_for_config(data, signal_type, expected_direction)

            if signal is None:
                signals_no_match += 1
                continue

            lock_key = f"{symbol}:{signal_type}"
            if self._is_signal_locked(lock_key, crossover_origin):
                signals_locked += 1
                logger.debug(f"Signal locked for {lock_key}: crossover at {crossover_origin}")
                continue

            # Lifecycle check
            if self._lifecycle_client is not None:
                signal_id = f"{symbol.lower()}_{expected_direction.lower()}_{signal_type}_{signal_timeframe}"
                try:
                    if not self._lifecycle_client.is_signal_tradeable(signal_id):
                        logger.info(
                            f"Signal {signal_type} blocked: lifecycle state non-tradeable "
                            f"(signal_id={signal_id})"
                        )
                        continue
                except Exception as e:
                    logger.warning(
                        f"Lifecycle check failed for {signal_id}, allowing signal (fail-open): {e}"
                    )

            signals_triggered += 1
            logger.info(
                f"Signal triggered: {symbol} {signal_type} [{signal_timeframe}] -> {signal}"
            )
            triggered_results.append(
                self._create_entry_signal(symbol, signal, data, crossover_origin, signal_type, signal_timeframe)
            )
            # NO break â€” collect all triggered signals

        logger.debug(
            f"Batch signal evaluation for {symbol}: "
            f"checked={signals_checked}, triggered={signals_triggered}, "
            f"locked={signals_locked}, no_data={signals_no_data}, "
            f"no_match={signals_no_match}"
        )

        self._eval_cycle_count += 1
        self._total_triggered += signals_triggered
        self._total_locked += signals_locked
        self._emit_rate_limited_info_summary(symbol)

        return triggered_results

    def _emit_rate_limited_info_summary(self, symbol: str) -> None:
        """Emit a rate-limited INFO summary of signal health.

        Issue #585: Provides aggregate monitoring without flooding logs.
        Emits at most once every N cycles or every T seconds (whichever comes first).

        Args:
            symbol: Most recent symbol evaluated (for context).
        """
        now = time.monotonic()
        time_elapsed = now - self._last_info_summary_time
        cycle_due = (self._eval_cycle_count % self._info_summary_cycle_interval) == 0
        time_due = time_elapsed >= self._info_summary_time_interval

        if cycle_due or time_due:
            logger.info(
                f"Signal health summary: "
                f"total_evaluations={self._eval_cycle_count}, "
                f"total_triggered={self._total_triggered}, "
                f"total_locked={self._total_locked}, "
                f"last_symbol={symbol}"
            )
            self._last_info_summary_time = now

    def _create_entry_signal(
        self, symbol: str, signal: str, data: pd.DataFrame,
        crossover_origin: datetime, signal_source: str, timeframe: str = "D1"
    ) -> HybridEntrySignal:
        """Create an entry signal object.

        Args:
            symbol: Trading symbol
            signal: Direction (LONG/SHORT)
            data: Market data DataFrame
            crossover_origin: Timestamp of the signal trigger
            signal_source: Name of the signal that triggered
            timeframe: Timeframe of the signal (M30, H1, H2, etc.)

        Returns:
            HybridEntrySignal object
        """
        # Calculate confidence
        confidence = self._calculate_confidence(data)

        # Get latest candle time
        candle_time = data["timestamp"].iloc[-1]
        if isinstance(candle_time, pd.Timestamp):
            candle_time = candle_time.to_pydatetime()
        if candle_time.tzinfo is None:
            candle_time = candle_time.replace(tzinfo=timezone.utc)

        # Convert crossover_origin
        if isinstance(crossover_origin, pd.Timestamp):
            crossover_origin = crossover_origin.to_pydatetime()
        if crossover_origin.tzinfo is None:
            crossover_origin = crossover_origin.replace(tzinfo=timezone.utc)

        entry_signal = HybridEntrySignal(
            symbol=symbol,
            direction=signal,
            confidence=confidence,
            timestamp=datetime.now(timezone.utc),
            candle_time=candle_time,
            crossover_origin=crossover_origin,
            signal_source=signal_source,
            timeframe=timeframe,
        )

        logger.info(
            f"Entry signal: {symbol} {signal} (conf={confidence:.2f}, "
            f"crossover={crossover_origin}, source={signal_source}, timeframe={timeframe})"
        )

        return entry_signal

    def _is_signal_locked(self, lock_key: str, crossover_origin: datetime) -> bool:
        """Check if a specific signal is locked.

        Args:
            lock_key: Lock key in format "SYMBOL:signal_type"
            crossover_origin: Timestamp of the crossover

        Returns:
            True if signal is locked for this crossover
        """
        last_traded = self._last_traded_crossover.get(lock_key)
        if last_traded is None:
            return False
        return crossover_origin <= last_traded

    def lock_signal(
        self, symbol: str, crossover_origin: datetime, signal_source: str
    ) -> None:
        """Lock a signal to prevent re-entry on the same crossover.

        Called by main.py after a position is successfully opened.
        This prevents the same signal from triggering multiple positions.

        Args:
            symbol: Trading symbol (e.g., "EURUSD")
            crossover_origin: Timestamp when the crossover occurred
            signal_source: Signal type name (e.g., "SMA20_50_BB_long")
        """
        lock_key = f"{symbol}:{signal_source}"
        self._last_traded_crossover[lock_key] = crossover_origin
        logger.info(
            f"Signal locked: {lock_key} at crossover {crossover_origin}"
        )

    def _detect_signal_for_config(
        self, df: pd.DataFrame, signal_type: str, expected_direction: str
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect a specific signal type.

        Issue #561: Now uses dynamic SignalParser first, falls back to hardcoded.

        Args:
            df: DataFrame with indicator data
            signal_type: Signal type name (e.g., "SMA50_200_RSI_Stoch_long")
            expected_direction: Expected direction ("LONG" or "SHORT")

        Returns:
            (signal, crossover_origin) or (None, None)
        """
        if len(df) == 0:
            return None, None

        # Issue #585: Log which handler is being attempted
        logger.debug(f"Checking signal {signal_type} via handler...")

        # Issue #561: Try dynamic signal detection first
        if self._signal_parser and self._signal_parser.is_dynamic_signal(signal_type):
            signal, timestamp = self._signal_parser.evaluate_signal(signal_type, df)
            if signal:
                logger.debug(f"Dynamic detection: {signal_type} -> {signal}")
                return signal, timestamp
            return None, None

        # Fallback to hardcoded handlers for legacy/special signals
        if signal_type == "EMA12_cross_EMA26":
            return self._detect_ema_crossover(df, expected_direction)
        elif signal_type in ("ATR_breakout", "ATR_breakout_up", "ATR_breakout_down"):
            return self._detect_atr_breakout(df, expected_direction)
        elif signal_type == "BB_squeeze":
            return self._detect_bb_squeeze(df, expected_direction)
        elif signal_type == "RSI14_extreme_oversold":
            return self._detect_rsi_extreme_oversold(df)
        elif signal_type == "RSI14_very_extreme_oversold":
            return self._detect_rsi_very_extreme_oversold(df)
        elif signal_type == "RSI14_extreme_overbought":
            return self._detect_rsi_extreme_overbought(df)
        elif signal_type == "BB_upper_AND_RSI_overbought":
            return self._detect_bb_upper_and_rsi_overbought(df)
        elif signal_type == "BB_upper_cross_down":
            return self._detect_bb_upper_cross_down(df)
        elif signal_type == "MACD_cross_down_AND_RSI_above_50":
            return self._detect_macd_cross_down_rsi_above_50(df)
        # Hybrid V4 trained signal types
        elif signal_type == "RSI_oversold_long":
            return self._detect_rsi_oversold_long(df)
        elif signal_type == "SMA50_200_RSI_Stoch_long":
            return self._detect_sma50_200_rsi_stoch_long(df)
        elif signal_type == "Stoch_RSI_long_15_25":
            return self._detect_stoch_rsi_long(df, stoch_thresh=15, rsi_thresh=25)
        elif signal_type == "Stoch_RSI_long_15_30":
            return self._detect_stoch_rsi_long(df, stoch_thresh=15, rsi_thresh=30)
        elif signal_type == "Stoch_RSI_long_15_35":
            return self._detect_stoch_rsi_long(df, stoch_thresh=15, rsi_thresh=35)
        elif signal_type == "Stoch_RSI_long_20_30":
            return self._detect_stoch_rsi_long(df, stoch_thresh=20, rsi_thresh=30)
        elif signal_type == "Stoch_RSI_long_20_35":
            return self._detect_stoch_rsi_long(df, stoch_thresh=20, rsi_thresh=35)
        # Missing Stoch_RSI variants
        elif signal_type == "Stoch_RSI_long_20_25":
            return self._detect_stoch_rsi_long(df, stoch_thresh=20, rsi_thresh=25)
        elif signal_type == "Stoch_RSI_short_20_30":
            return self._detect_stoch_rsi_short(df, stoch_thresh=80, rsi_thresh=70)
        # MACD + Stochastic combinations
        elif signal_type == "MACD_Stoch_long":
            return self._detect_macd_stoch_long(df)
        elif signal_type == "MACD_Stoch_short":
            return self._detect_macd_stoch_short(df)
        # Triple Momentum signal
        elif signal_type == "Triple_Momentum_long":
            return self._detect_triple_momentum_long(df)
        # SMA + BB combinations
        elif signal_type == "SMA20_50_BB_short":
            return self._detect_sma20_50_bb_short(df)
        elif signal_type == "SMA50_200_Stoch_BB_short":
            return self._detect_sma50_200_stoch_bb_short(df)
        elif signal_type == "SMA20_200_BB_long":
            return self._detect_sma20_200_bb_long(df)
        # SMA + MACD combinations
        elif signal_type == "SMA20_50_MACD_long":
            return self._detect_sma20_50_macd_long(df)
        # Complex multi-indicator signals
        elif signal_type == "SMA20_50_RSI_Stoch_BB_short":
            return self._detect_sma20_50_rsi_stoch_bb_short(df)
        elif signal_type == "SMA20_200_Stoch_short":
            return self._detect_sma20_200_stoch_short(df)
        # Additional EURCAD signals
        elif signal_type == "MACD_cross_long":
            return self._detect_macd_cross_long(df)
        elif signal_type == "SMA20_50_RSI_long":
            return self._detect_sma20_50_rsi_long(df)
        # Additional signals - Issue #560
        elif signal_type == "Stoch_K_oversold_long_25":
            return self._detect_stoch_k_oversold_long(df, stoch_thresh=25)
        elif signal_type == "SMA20_50_BB_long":
            return self._detect_sma20_50_bb_long(df)
        # New signals - Batch deployment
        elif signal_type == "SMA20_200_RSI_Stoch_long":
            return self._detect_sma20_200_rsi_stoch_long(df)
        elif signal_type == "SMA20_200_RSI_Stoch_short":
            return self._detect_sma20_200_rsi_stoch_short(df)
        elif signal_type == "SMA20_200_Stoch_BB_short":
            return self._detect_sma20_200_stoch_bb_short(df)
        elif signal_type == "SMA20_50_Stoch_BB_short":
            return self._detect_sma20_50_stoch_bb_short(df)
        elif signal_type == "SMA50_200_RSI_Stoch_BB_short":
            return self._detect_sma50_200_rsi_stoch_bb_short(df)
        elif signal_type == "SMA50_200_RSI_Stoch_short":
            return self._detect_sma50_200_rsi_stoch_short(df)
        elif signal_type == "SMA_20_50_cross_short":
            return self._detect_sma_20_50_cross_short(df)
        # Issue #585: Missing signal handlers
        elif signal_type == "EMA_RSI_long":
            return self._detect_ema_rsi_long(df)
        elif signal_type == "SMA20_200_RSI_long":
            return self._detect_sma20_200_rsi_long(df)
        elif signal_type == "SMA50_200_RSI_Stoch_BB_long":
            return self._detect_sma50_200_rsi_stoch_bb_long(df)
        # Issue #604: RSI + BB confluence signals (USDCHF, EURGBP)
        elif signal_type == "RSI_BB_confluence_long":
            return self._detect_rsi_bb_confluence_long(df)
        elif signal_type == "RSI_BB_confluence_short":
            return self._detect_rsi_bb_confluence_short(df)
        else:
            logger.warning(f"Unknown signal type: {signal_type}. Add to config/signal_definitions.yaml")
            return None, None

    def confirm_entry(
        self, symbol: str, crossover_origin: datetime, signal_source: Optional[str] = None
    ) -> None:
        """Confirm entry was taken, lock the crossover.

        Called after position is actually opened to prevent
        re-entry on same crossover.

        Args:
            symbol: Trading symbol
            crossover_origin: Crossover timestamp to lock
            signal_source: Optional signal type name for per-signal locking
        """
        symbol = symbol.upper()
        if signal_source:
            # Per-signal locking (new multi-signal mode)
            lock_key = f"{symbol}:{signal_source}"
        else:
            # Legacy symbol-level locking
            lock_key = symbol

        self._last_traded_crossover[lock_key] = crossover_origin
        logger.debug(f"Locked crossover for {lock_key}: {crossover_origin}")

    def poll_all_symbols(self) -> List[HybridEntrySignal]:
        """Poll all symbols for entry signals.

        Issue #569 Stream E: Proactively pre-fetches ALL timeframes for ALL symbols.

        Returns:
            List of entry signals (may be empty)
        """
        # Issue #569 Stream E: Pre-fetch ALL timeframes for ALL symbols proactively
        # This ensures infrastructure is ready as more models are trained
        self._prefetch_all_timeframes()

        signals = []
        for symbol in self.symbols:
            try:
                signal = self.evaluate_entry(symbol)
                if signal:
                    signals.append(signal)
            except Exception as e:
                logger.error(f"Error evaluating {symbol}: {e}")
        return signals

    def _prefetch_all_timeframes(self) -> None:
        """Proactively pre-fetch data for ALL timeframes for ALL symbols.

        Issue #569 Stream E: This method ensures all timeframe data is cached
        and ready for signal evaluation, regardless of which signals are
        currently configured. As more models are trained, data will already
        be available.

        This method:
        1. Iterates through ALL enabled symbols
        2. For each symbol, fetches ALL 9 supported timeframes
        3. Logs data availability summary

        Data is cached with appropriate timeouts per timeframe (see TIMEFRAME_CACHE_TIMEOUT).
        """
        if self.db is None:
            logger.warning("No database connection - skipping timeframe prefetch")
            return

        total_fetched = 0
        total_failed = 0
        availability_summary = {}

        for symbol in self.symbols:
            symbol_status = {}
            for timeframe in SUPPORTED_TIMEFRAMES:
                try:
                    # Use existing fetch method - it handles caching internally
                    data = self._fetch_timeframe_data(symbol, timeframe)
                    if data is not None and len(data) > 0:
                        symbol_status[timeframe] = len(data)
                        total_fetched += 1
                    else:
                        symbol_status[timeframe] = 0
                        total_failed += 1
                except Exception as e:
                    logger.debug(f"Prefetch failed for {symbol} {timeframe}: {e}")
                    symbol_status[timeframe] = 0
                    total_failed += 1

            availability_summary[symbol] = symbol_status

        # Log summary (compact format)
        logger.info(
            f"Timeframe prefetch complete: {total_fetched} available, "
            f"{total_failed} unavailable across {len(self.symbols)} symbols"
        )

        # Detailed per-symbol logging (debug level)
        for symbol, status in availability_summary.items():
            available = [tf for tf, rows in status.items() if rows > 0]
            missing = [tf for tf, rows in status.items() if rows == 0]
            if missing:
                logger.debug(
                    f"{symbol}: available={available}, missing={missing}"
                )

    def _fetch_d1_data(self, symbol: str) -> Optional[pd.DataFrame]:
        """Fetch D1 indicator data from database.

        Args:
            symbol: Trading symbol

        Returns:
            DataFrame with D1 indicators or None
        """
        if self.db is None:
            logger.warning("No database connection available")
            return None

        # Check cache freshness (D1 data changes slowly)
        now = datetime.now(timezone.utc)
        if symbol in self._cache_timestamp:
            cache_age = (now - self._cache_timestamp[symbol]).total_seconds()
            if cache_age < 3600:  # Cache valid for 1 hour
                return self._d1_cache.get(symbol)

        # Build query
        table = D1_INDICATOR_TABLES.get(symbol, f"technical_indicator_{symbol.lower()}")
        query = f"""
            SELECT timestamp, sma_20, sma_50, ema_12, ema_26, rsi_14, atr_14
            FROM {table}
            WHERE timeframe = 'D1' AND symbol = :symbol
            ORDER BY timestamp DESC
            LIMIT 20
        """

        try:
            result = self.db.execute_query("ai_model", query, {"symbol": symbol})
            if not result:
                return None

            df = pd.DataFrame(result)
            df["timestamp"] = pd.to_datetime(df["timestamp"])

            # Convert Decimal columns to float for numpy compatibility
            numeric_cols = ["sma_20", "sma_50", "ema_12", "ema_26", "rsi_14", "atr_14"]
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = df[col].astype(float)

            df = df.sort_values("timestamp").reset_index(drop=True)

            # Compute crossover signals
            df = self._compute_crossover_signals(df)

            # Update cache
            self._d1_cache[symbol] = df
            self._cache_timestamp[symbol] = now

            return df

        except Exception as e:
            logger.error(f"Error fetching D1 data for {symbol}: {e}")
            return None

    def _fetch_timeframe_data(
        self, symbol: str, timeframe: Optional[str] = None
    ) -> Optional[pd.DataFrame]:
        """Fetch data for a specific or the configured timeframe.

        Supports ALL timeframes: M30, H1, H2, H3, H4, H6, H8, H12, D1.
        Issue #569: Extended from D1/H4 only to support all timeframes.
        Issue #569 Stream C: Added optional timeframe parameter for per-signal fetching.

        Strategy:
        1. First try direct database query for the timeframe
        2. If not available, fall back to M30 aggregation

        Args:
            symbol: Trading symbol
            timeframe: Optional timeframe override. If None, uses self.timeframe.

        Returns:
            DataFrame with indicator data or None
        """
        # Use provided timeframe or fall back to evaluator's default
        effective_timeframe = timeframe if timeframe is not None else self.timeframe

        # Validate timeframe is supported
        if effective_timeframe not in SUPPORTED_TIMEFRAMES:
            logger.warning(f"Unsupported timeframe: {effective_timeframe}")
            return None

        # D1 uses special handling (existing implementation)
        if effective_timeframe == "D1":
            return self._fetch_d1_data(symbol)

        # Issue #585: All non-D1 timeframes (including H4) use the generic path.
        # The generic path tries _query_timeframe_direct() first, which returns
        # pre-computed indicators (RSI, Stoch, SMA, BB, MACD) from the ai_model DB.
        # The old _fetch_h4_data() M30 aggregation path only computed EMA/ATR,
        # missing all indicators needed by Hybrid V4 signal handlers.
        return self._fetch_generic_timeframe_data(symbol, effective_timeframe)

    def _fetch_generic_timeframe_data(
        self, symbol: str, timeframe: str
    ) -> Optional[pd.DataFrame]:
        """Fetch data for any supported timeframe (M30-H12).

        Issue #569: New method to support all timeframes.

        Strategy:
        1. Try direct query to database for the timeframe
        2. If data exists, return it
        3. If not, fall back to M30 aggregation

        Args:
            symbol: Trading symbol
            timeframe: Timeframe string (M30, H1, H2, H3, H4, H6, H8, H12)

        Returns:
            DataFrame with OHLCV and indicators or None
        """
        if self.db is None:
            logger.warning("No database connection available")
            return None

        # Check cache freshness
        now = datetime.now(timezone.utc)
        cache_key = f"{symbol}_{timeframe}"
        cache_timeout = TIMEFRAME_CACHE_TIMEOUT.get(timeframe, 1800)

        if cache_key in self._cache_timestamp:
            cache_age = (now - self._cache_timestamp[cache_key]).total_seconds()
            if cache_age < cache_timeout:
                return self._timeframe_cache.get(cache_key)

        # Try direct database query first
        df = self._query_timeframe_direct(symbol, timeframe)

        if df is not None and len(df) > 0:
            # Compute indicators if needed
            df = self._compute_generic_indicators(df, timeframe)

            # Update cache
            self._timeframe_cache[cache_key] = df
            self._cache_timestamp[cache_key] = now

            logger.debug(
                f"Fetched {len(df)} {timeframe} bars for {symbol} (direct query)"
            )
            return df

        # Fallback: Aggregate from M30 data
        logger.debug(
            f"Direct query returned no data for {symbol} {timeframe}, "
            f"falling back to M30 aggregation"
        )
        df = self._fetch_aggregated_timeframe_data(symbol, timeframe)

        if df is not None and len(df) > 0:
            # Update cache
            self._timeframe_cache[cache_key] = df
            self._cache_timestamp[cache_key] = now

        return df

    def _query_timeframe_direct(
        self, symbol: str, timeframe: str
    ) -> Optional[pd.DataFrame]:
        """Query database directly for timeframe data.

        Args:
            symbol: Trading symbol
            timeframe: Timeframe string

        Returns:
            DataFrame with data or None
        """
        table = M30_INDICATOR_TABLES.get(
            symbol, f"technical_indicator_{symbol.lower()}"
        )

        # Query with all available indicator columns (column names match database schema)
        query = f"""
            SELECT timestamp, open, high, low, close, volume,
                   sma_20, sma_50, ema_12, ema_26, rsi_14, atr_14,
                   stoch_k, stoch_d, macd_line AS macd, macd_signal,
                   bb_upper_20 AS bb_upper, bb_lower_20 AS bb_lower, bb_middle_20 AS bb_middle
            FROM {table}
            WHERE timeframe = :timeframe AND symbol = :symbol
            ORDER BY timestamp DESC
            LIMIT 50
        """

        try:
            result = self.db.execute_query(
                "ai_model", query, {"timeframe": timeframe, "symbol": symbol}
            )
            if not result:
                return None

            df = pd.DataFrame(result)
            df["timestamp"] = pd.to_datetime(df["timestamp"])

            # Convert Decimal columns to float
            numeric_cols = [
                "open", "high", "low", "close", "volume",
                "sma_20", "sma_50", "ema_12", "ema_26", "rsi_14", "atr_14",
                "stoch_k", "stoch_d", "macd", "macd_signal",
                "bb_upper", "bb_lower", "bb_middle",
            ]
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors="coerce")

            df = df.sort_values("timestamp").reset_index(drop=True)
            return df

        except Exception as e:
            logger.debug(f"Direct query failed for {symbol} {timeframe}: {e}")
            return None

    def _fetch_aggregated_timeframe_data(
        self, symbol: str, timeframe: str
    ) -> Optional[pd.DataFrame]:
        """Fetch timeframe data by aggregating M30 bars.

        Used as fallback when direct query doesn't return data.

        Args:
            symbol: Trading symbol
            timeframe: Target timeframe

        Returns:
            DataFrame with aggregated OHLCV and indicators or None
        """
        # Determine how many M30 bars needed
        m30_multiplier = M30_BARS_PER_TIMEFRAME.get(timeframe, 2)
        bars_needed = 50 * m30_multiplier  # 50 target bars * M30 per bar

        # Fetch M30 data
        m30_df = self._fetch_m30_data_with_limit(symbol, bars_needed)
        if m30_df is None or len(m30_df) < m30_multiplier:
            return None

        # Aggregate to target timeframe
        aggregated_df = self._aggregate_to_timeframe(m30_df, timeframe)
        if aggregated_df is None or len(aggregated_df) < 2:
            return None

        # Compute indicators
        aggregated_df = self._compute_generic_indicators(aggregated_df, timeframe)

        return aggregated_df

    def _fetch_m30_data_with_limit(
        self, symbol: str, limit: int
    ) -> Optional[pd.DataFrame]:
        """Fetch M30 data with specified limit.

        Args:
            symbol: Trading symbol
            limit: Number of M30 bars to fetch

        Returns:
            DataFrame with M30 data or None
        """
        if self.db is None:
            return None

        table = M30_INDICATOR_TABLES.get(
            symbol, f"technical_indicator_{symbol.lower()}"
        )

        query = f"""
            SELECT timestamp, open, high, low, close, volume
            FROM {table}
            WHERE timeframe = 'M30' AND symbol = :symbol
            ORDER BY timestamp DESC
            LIMIT :limit
        """

        try:
            result = self.db.execute_query(
                "ai_model", query, {"symbol": symbol, "limit": limit}
            )
            if not result:
                return None

            df = pd.DataFrame(result)
            df["timestamp"] = pd.to_datetime(df["timestamp"])

            numeric_cols = ["open", "high", "low", "close", "volume"]
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors="coerce")

            df = df.sort_values("timestamp").reset_index(drop=True)
            return df

        except Exception as e:
            logger.error(f"Error fetching M30 data for {symbol}: {e}")
            return None

    def _aggregate_to_timeframe(
        self, m30_df: pd.DataFrame, timeframe: str
    ) -> Optional[pd.DataFrame]:
        """Aggregate M30 data to target timeframe.

        Args:
            m30_df: DataFrame with M30 OHLCV data
            timeframe: Target timeframe (H1, H2, H3, H4, H6, H8, H12)

        Returns:
            DataFrame with aggregated OHLCV or None
        """
        if m30_df is None or len(m30_df) == 0:
            return None

        # Map timeframe to pandas floor unit
        floor_map = {
            "M30": "30min",
            "H1": "1h",
            "H2": "2h",
            "H3": "3h",
            "H4": "4h",
            "H6": "6h",
            "H8": "8h",
            "H12": "12h",
        }

        floor_unit = floor_map.get(timeframe)
        if floor_unit is None:
            logger.warning(f"Cannot aggregate to timeframe: {timeframe}")
            return None

        # Ensure timestamp is datetime
        if not pd.api.types.is_datetime64_any_dtype(m30_df["timestamp"]):
            m30_df["timestamp"] = pd.to_datetime(m30_df["timestamp"])

        # Make timezone-aware if not already
        if m30_df["timestamp"].dt.tz is None:
            m30_df["timestamp"] = m30_df["timestamp"].dt.tz_localize("UTC")

        # Floor to timeframe boundary
        m30_df["tf_group"] = m30_df["timestamp"].dt.floor(floor_unit)

        # Aggregate OHLCV
        agg_df = (
            m30_df.groupby("tf_group")
            .agg({
                "open": "first",
                "high": "max",
                "low": "min",
                "close": "last",
                "volume": "sum",
            })
            .reset_index()
        )

        agg_df.rename(columns={"tf_group": "timestamp"}, inplace=True)
        agg_df = agg_df.sort_values("timestamp").reset_index(drop=True)

        return agg_df

    def _compute_generic_indicators(
        self, df: pd.DataFrame, timeframe: str
    ) -> pd.DataFrame:
        """Compute indicators on timeframe data.

        Computes EMA, ATR, and crossover detection columns.

        Args:
            df: DataFrame with OHLCV data
            timeframe: Timeframe string (for logging)

        Returns:
            DataFrame with indicators added
        """
        if len(df) < 2:
            return df

        # Check if indicators already exist
        if "ema_12" in df.columns and "ema_26" in df.columns:
            # Indicators already present, just compute crossover signals
            pass
        else:
            # Compute EMA
            df["ema_12"] = df["close"].ewm(span=12, adjust=False).mean()
            df["ema_26"] = df["close"].ewm(span=26, adjust=False).mean()

        # Compute ATR if not present
        if "atr_14" not in df.columns or df["atr_14"].isna().all():
            df["tr"] = np.maximum(
                df["high"] - df["low"],
                np.maximum(
                    np.abs(df["high"] - df["close"].shift(1)),
                    np.abs(df["low"] - df["close"].shift(1)),
                ),
            )
            df["atr_14"] = df["tr"].rolling(window=14, min_periods=1).mean()

        # EMA crossover detection
        df["ema12_above_ema26"] = df["ema_12"] > df["ema_26"]

        df["ema_cross_up"] = (df["ema12_above_ema26"] == True) & (
            df["ema12_above_ema26"].shift(1) == False
        )
        df["ema_cross_down"] = (df["ema12_above_ema26"] == False) & (
            df["ema12_above_ema26"].shift(1) == True
        )

        # Recent crossovers
        df["recent_ema_cross_up"] = (
            df["ema_cross_up"]
            .rolling(window=self.cross_lookback, min_periods=1)
            .max()
            .fillna(0)
            .astype(bool)
        )

        df["recent_ema_cross_down"] = (
            df["ema_cross_down"]
            .rolling(window=self.cross_lookback, min_periods=1)
            .max()
            .fillna(0)
            .astype(bool)
        )

        # Price change for ATR breakout
        df["price_change"] = df["close"] - df["close"].shift(1)
        df["price_change_atr"] = df["price_change"] / df["atr_14"]

        return df

    def _fetch_h4_data(self, symbol: str) -> Optional[pd.DataFrame]:
        """Fetch H4 data by aggregating M30 bars.

        Args:
            symbol: Trading symbol

        Returns:
            DataFrame with H4 OHLCV and indicators or None
        """
        if self.db is None:
            logger.warning("No database connection available")
            return None

        # Check cache freshness (H4 data: cache for 30 minutes)
        now = datetime.now(timezone.utc)
        cache_key = f"{symbol}_h4"
        if cache_key in self._cache_timestamp:
            cache_age = (now - self._cache_timestamp[cache_key]).total_seconds()
            if cache_age < 1800:  # Cache valid for 30 minutes
                return self._h4_cache.get(symbol)

        # Fetch M30 data
        m30_data = self._fetch_m30_data(symbol)
        if m30_data is None:
            return None

        # Aggregate to H4
        h4_df = self._aggregate_m30_to_h4(m30_data)
        if h4_df is None or len(h4_df) < 2:
            return None

        # Compute H4 indicators
        h4_df = self._compute_h4_indicators(h4_df)

        # Update cache
        self._h4_cache[symbol] = h4_df
        self._cache_timestamp[cache_key] = now

        return h4_df

    def _fetch_m30_data(self, symbol: str) -> Optional[pd.DataFrame]:
        """Fetch M30 data from database.

        Args:
            symbol: Trading symbol

        Returns:
            DataFrame with M30 OHLCV data or None
        """
        if self.db is None:
            return None

        table = M30_INDICATOR_TABLES.get(
            symbol, f"technical_indicator_{symbol.lower()}"
        )

        # Fetch enough M30 bars to create ~20 H4 bars (160 M30 bars)
        query = f"""
            SELECT timestamp, open, high, low, close, volume
            FROM {table}
            WHERE timeframe = 'M30' AND symbol = :symbol
            ORDER BY timestamp DESC
            LIMIT 160
        """

        try:
            result = self.db.execute_query("ai_model", query, {"symbol": symbol})
            if not result:
                return None

            df = pd.DataFrame(result)
            df["timestamp"] = pd.to_datetime(df["timestamp"])

            # Convert Decimal columns to float for numpy compatibility
            numeric_cols = ["open", "high", "low", "close", "volume"]
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = df[col].astype(float)

            df = df.sort_values("timestamp").reset_index(drop=True)

            return df

        except Exception as e:
            logger.error(f"Error fetching M30 data for {symbol}: {e}")
            return None

    def _aggregate_m30_to_h4(self, m30_df: pd.DataFrame) -> Optional[pd.DataFrame]:
        """Aggregate M30 OHLCV to H4 bars.

        8 M30 bars = 1 H4 bar.

        Args:
            m30_df: DataFrame with M30 OHLCV data

        Returns:
            DataFrame with H4 OHLCV data or None
        """
        if m30_df is None or len(m30_df) == 0:
            return None

        # Ensure timestamp is datetime
        if not pd.api.types.is_datetime64_any_dtype(m30_df["timestamp"]):
            m30_df["timestamp"] = pd.to_datetime(m30_df["timestamp"])

        # Make timezone-aware if not already
        if m30_df["timestamp"].dt.tz is None:
            m30_df["timestamp"] = m30_df["timestamp"].dt.tz_localize("UTC")

        # Floor to H4 boundary (4 hours)
        m30_df["h4_group"] = m30_df["timestamp"].dt.floor("4h")

        # Aggregate
        h4_df = (
            m30_df.groupby("h4_group")
            .agg(
                {
                    "open": "first",
                    "high": "max",
                    "low": "min",
                    "close": "last",
                    "volume": "sum",
                }
            )
            .reset_index()
        )

        h4_df.rename(columns={"h4_group": "timestamp"}, inplace=True)
        h4_df = h4_df.sort_values("timestamp").reset_index(drop=True)

        return h4_df

    def _compute_h4_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """Compute indicators on H4 data.

        Computes:
        - EMA12, EMA26 (for crossover)
        - ATR14 (for breakout)
        - Crossover detection columns

        Args:
            df: DataFrame with H4 OHLCV data

        Returns:
            DataFrame with indicators added
        """
        if len(df) < 2:
            return df

        # Compute EMA
        df["ema_12"] = df["close"].ewm(span=12, adjust=False).mean()
        df["ema_26"] = df["close"].ewm(span=26, adjust=False).mean()

        # Compute ATR
        df["tr"] = np.maximum(
            df["high"] - df["low"],
            np.maximum(
                np.abs(df["high"] - df["close"].shift(1)),
                np.abs(df["low"] - df["close"].shift(1)),
            ),
        )
        df["atr_14"] = df["tr"].rolling(window=14, min_periods=1).mean()

        # EMA crossover detection
        df["ema12_above_ema26"] = df["ema_12"] > df["ema_26"]

        df["ema_cross_up"] = (df["ema12_above_ema26"] == True) & (
            df["ema12_above_ema26"].shift(1) == False
        )
        df["ema_cross_down"] = (df["ema12_above_ema26"] == False) & (
            df["ema12_above_ema26"].shift(1) == True
        )

        # Recent crossovers
        df["recent_ema_cross_up"] = (
            df["ema_cross_up"]
            .rolling(window=self.cross_lookback, min_periods=1)
            .max()
            .fillna(0)
            .astype(bool)
        )

        df["recent_ema_cross_down"] = (
            df["ema_cross_down"]
            .rolling(window=self.cross_lookback, min_periods=1)
            .max()
            .fillna(0)
            .astype(bool)
        )

        # Price change for ATR breakout
        df["price_change"] = df["close"] - df["close"].shift(1)
        df["price_change_atr"] = df["price_change"] / df["atr_14"]

        return df

    def _detect_signal(
        self, df: pd.DataFrame, symbol: str
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect signal based on symbol configuration.

        Args:
            df: DataFrame with indicator data
            symbol: Trading symbol

        Returns:
            (signal, crossover_origin) or (None, None)
        """
        if len(df) == 0:
            return None, None

        # Get signal config for symbol
        config = self.signal_config.get(symbol, {})
        signal_type = config.get("signal", "EMA12_cross_EMA26")
        expected_direction = config.get("direction", "long").upper()

        if signal_type == "EMA12_cross_EMA26":
            return self._detect_ema_crossover(df, expected_direction)
        elif signal_type in ("ATR_breakout", "ATR_breakout_up", "ATR_breakout_down"):
            return self._detect_atr_breakout(df, expected_direction)
        elif signal_type == "BB_squeeze":
            return self._detect_bb_squeeze(df, expected_direction)
        elif signal_type == "RSI14_extreme_oversold":
            return self._detect_rsi_extreme_oversold(df)
        elif signal_type == "RSI14_very_extreme_oversold":
            return self._detect_rsi_very_extreme_oversold(df)
        elif signal_type == "RSI14_extreme_overbought":
            return self._detect_rsi_extreme_overbought(df)
        elif signal_type == "BB_upper_AND_RSI_overbought":
            return self._detect_bb_upper_and_rsi_overbought(df)
        elif signal_type == "BB_upper_cross_down":
            return self._detect_bb_upper_cross_down(df)
        elif signal_type == "MACD_cross_down_AND_RSI_above_50":
            return self._detect_macd_cross_down_rsi_above_50(df)
        # Hybrid V4 trained signal types
        elif signal_type == "RSI_oversold_long":
            return self._detect_rsi_oversold_long(df)
        elif signal_type == "SMA50_200_RSI_Stoch_long":
            return self._detect_sma50_200_rsi_stoch_long(df)
        elif signal_type == "Stoch_RSI_long_15_30":
            return self._detect_stoch_rsi_long(df, stoch_thresh=15, rsi_thresh=30)
        elif signal_type == "Stoch_RSI_long_15_25":
            return self._detect_stoch_rsi_long(df, stoch_thresh=15, rsi_thresh=25)
        elif signal_type == "Stoch_RSI_long_15_35":
            return self._detect_stoch_rsi_long(df, stoch_thresh=15, rsi_thresh=35)
        elif signal_type == "Stoch_RSI_long_20_30":
            return self._detect_stoch_rsi_long(df, stoch_thresh=20, rsi_thresh=30)
        elif signal_type == "Stoch_RSI_long_20_35":
            return self._detect_stoch_rsi_long(df, stoch_thresh=20, rsi_thresh=35)
        # Missing Stoch_RSI variants
        elif signal_type == "Stoch_RSI_long_20_25":
            return self._detect_stoch_rsi_long(df, stoch_thresh=20, rsi_thresh=25)
        elif signal_type == "Stoch_RSI_short_20_30":
            return self._detect_stoch_rsi_short(df, stoch_thresh=80, rsi_thresh=70)
        # MACD + Stochastic combinations
        elif signal_type == "MACD_Stoch_long":
            return self._detect_macd_stoch_long(df)
        elif signal_type == "MACD_Stoch_short":
            return self._detect_macd_stoch_short(df)
        # Triple Momentum signal
        elif signal_type == "Triple_Momentum_long":
            return self._detect_triple_momentum_long(df)
        # SMA + BB combinations
        elif signal_type == "SMA20_50_BB_short":
            return self._detect_sma20_50_bb_short(df)
        elif signal_type == "SMA50_200_Stoch_BB_short":
            return self._detect_sma50_200_stoch_bb_short(df)
        elif signal_type == "SMA20_200_BB_long":
            return self._detect_sma20_200_bb_long(df)
        # SMA + MACD combinations
        elif signal_type == "SMA20_50_MACD_long":
            return self._detect_sma20_50_macd_long(df)
        # Complex multi-indicator signals
        elif signal_type == "SMA20_50_RSI_Stoch_BB_short":
            return self._detect_sma20_50_rsi_stoch_bb_short(df)
        elif signal_type == "SMA20_200_Stoch_short":
            return self._detect_sma20_200_stoch_short(df)
        # Additional EURCAD signals
        elif signal_type == "MACD_cross_long":
            return self._detect_macd_cross_long(df)
        elif signal_type == "SMA20_50_RSI_long":
            return self._detect_sma20_50_rsi_long(df)
        # Additional signals - Issue #560
        elif signal_type == "Stoch_K_oversold_long_25":
            return self._detect_stoch_k_oversold_long(df, stoch_thresh=25)
        elif signal_type == "SMA20_50_BB_long":
            return self._detect_sma20_50_bb_long(df)
        # New signals - Batch deployment
        elif signal_type == "SMA20_200_RSI_Stoch_long":
            return self._detect_sma20_200_rsi_stoch_long(df)
        elif signal_type == "SMA20_200_RSI_Stoch_short":
            return self._detect_sma20_200_rsi_stoch_short(df)
        elif signal_type == "SMA20_200_Stoch_BB_short":
            return self._detect_sma20_200_stoch_bb_short(df)
        elif signal_type == "SMA20_50_Stoch_BB_short":
            return self._detect_sma20_50_stoch_bb_short(df)
        elif signal_type == "SMA50_200_RSI_Stoch_BB_short":
            return self._detect_sma50_200_rsi_stoch_bb_short(df)
        elif signal_type == "SMA50_200_RSI_Stoch_short":
            return self._detect_sma50_200_rsi_stoch_short(df)
        elif signal_type == "SMA_20_50_cross_short":
            return self._detect_sma_20_50_cross_short(df)
        # Issue #585: Missing signal handlers
        elif signal_type == "EMA_RSI_long":
            return self._detect_ema_rsi_long(df)
        elif signal_type == "SMA20_200_RSI_long":
            return self._detect_sma20_200_rsi_long(df)
        elif signal_type == "SMA50_200_RSI_Stoch_BB_long":
            return self._detect_sma50_200_rsi_stoch_bb_long(df)
        # Issue #604: RSI + BB confluence signals (USDCHF, EURGBP)
        elif signal_type == "RSI_BB_confluence_long":
            return self._detect_rsi_bb_confluence_long(df)
        elif signal_type == "RSI_BB_confluence_short":
            return self._detect_rsi_bb_confluence_short(df)
        else:
            logger.warning(f"Unknown signal type: {signal_type}. Add to config/signal_definitions.yaml")
            return None, None

    def _detect_ema_crossover(
        self, df: pd.DataFrame, expected_direction: str
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect EMA12/EMA26 crossover signal.

        Args:
            df: DataFrame with EMA columns
            expected_direction: Expected direction ("LONG" or "SHORT")

        Returns:
            (signal, crossover_origin) or (None, None)
        """
        if len(df) == 0:
            return None, None

        latest = df.iloc[-1]

        signal = None
        cross_col = None

        if expected_direction == "LONG":
            if latest.get("recent_ema_cross_up", False):
                signal = SIGNAL_LONG
                cross_col = "ema_cross_up"
        elif expected_direction == "SHORT":
            if latest.get("recent_ema_cross_down", False):
                signal = SIGNAL_SHORT
                cross_col = "ema_cross_down"

        if signal is None:
            return None, None

        # Find crossover origin
        lookback = df.tail(self.cross_lookback)
        cross_mask = lookback[cross_col] == True
        if cross_mask.any():
            origin_row = lookback[cross_mask].iloc[0]
            origin_ts = origin_row["timestamp"]
        else:
            origin_ts = lookback.iloc[0]["timestamp"]

        return signal, origin_ts

    def _detect_atr_breakout(
        self, df: pd.DataFrame, expected_direction: str
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect ATR breakout signal.

        An ATR breakout occurs when price moves more than
        ATR_BREAKOUT_THRESHOLD * ATR in a single bar.

        Args:
            df: DataFrame with ATR and price change columns
            expected_direction: Expected direction ("LONG" or "SHORT")

        Returns:
            (signal, crossover_origin) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]
        price_change_atr = latest.get("price_change_atr", 0)

        if price_change_atr is None or np.isnan(price_change_atr):
            return None, None

        signal = None
        origin_ts = latest.get("timestamp")

        if expected_direction == "LONG":
            # Breakout up: price moved up more than threshold * ATR
            if price_change_atr >= ATR_BREAKOUT_THRESHOLD:
                signal = SIGNAL_LONG
        elif expected_direction == "SHORT":
            # Breakout down: price moved down more than threshold * ATR
            if price_change_atr <= -ATR_BREAKOUT_THRESHOLD:
                signal = SIGNAL_SHORT

        if signal is None:
            return None, None

        return signal, origin_ts

    def _detect_bb_squeeze(
        self, df: pd.DataFrame, expected_direction: str
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect Bollinger Bands squeeze signal.

        A BB squeeze indicates low volatility, often preceding a breakout.
        Signal is generated when BB width is below threshold and direction matches.

        Args:
            df: DataFrame with BB columns
            expected_direction: Expected direction ("LONG" or "SHORT")

        Returns:
            (signal, crossover_origin) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]
        close = latest.get("close", 0)

        # Compute BB if not present
        bb_upper = latest.get("bb_upper")
        bb_lower = latest.get("bb_lower")
        bb_middle = latest.get("bb_middle")

        if bb_upper is None or bb_lower is None:
            # Compute BB from recent data
            if len(df) >= BB_PERIOD:
                closes = df["close"].tail(BB_PERIOD)
                bb_middle = closes.mean()
                bb_std = closes.std()
                bb_upper = bb_middle + (BB_STD * bb_std)
                bb_lower = bb_middle - (BB_STD * bb_std)
            else:
                return None, None

        if bb_middle is None or bb_middle == 0:
            return None, None

        # BB width relative to middle
        bb_width = (bb_upper - bb_lower) / bb_middle

        if bb_width <= BB_SQUEEZE_THRESHOLD:
            # Squeeze detected - signal based on direction
            origin_ts = latest.get("timestamp")
            if expected_direction == "LONG":
                return SIGNAL_LONG, origin_ts
            elif expected_direction == "SHORT":
                return SIGNAL_SHORT, origin_ts

        return None, None

    def _detect_rsi_extreme_oversold(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect RSI extreme oversold condition (< 25).

        Args:
            df: DataFrame with RSI column

        Returns:
            (LONG signal, crossover_origin) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]
        rsi = latest.get("rsi_14", latest.get("rsi", None))

        if rsi is None or np.isnan(rsi):
            # Compute RSI if not present
            if len(df) >= 15:
                closes = df["close"].tail(15)
                delta = closes.diff()
                gain = (delta.where(delta > 0, 0)).mean()
                loss = (-delta.where(delta < 0, 0)).mean()
                if loss != 0:
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs))
                else:
                    rsi = 100
            else:
                return None, None

        origin_ts = latest.get("timestamp")

        if rsi <= RSI_OVERSOLD_THRESHOLD:
            return SIGNAL_LONG, origin_ts

        return None, None

    def _detect_rsi_very_extreme_oversold(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect RSI very extreme oversold condition (< 20).

        Args:
            df: DataFrame with RSI column

        Returns:
            (LONG signal, crossover_origin) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]
        rsi = latest.get("rsi_14", latest.get("rsi", None))

        if rsi is None or np.isnan(rsi):
            # Compute RSI if not present
            if len(df) >= 15:
                closes = df["close"].tail(15)
                delta = closes.diff()
                gain = (delta.where(delta > 0, 0)).mean()
                loss = (-delta.where(delta < 0, 0)).mean()
                if loss != 0:
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs))
                else:
                    rsi = 100
            else:
                return None, None

        origin_ts = latest.get("timestamp")

        if rsi <= RSI_VERY_OVERSOLD_THRESHOLD:
            return SIGNAL_LONG, origin_ts

        return None, None

    def _detect_rsi_extreme_overbought(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect RSI extreme overbought condition (> 75).

        Args:
            df: DataFrame with RSI column

        Returns:
            (SHORT signal, crossover_origin) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]
        rsi = latest.get("rsi_14", latest.get("rsi", None))

        if rsi is None or np.isnan(rsi):
            if len(df) >= 15:
                closes = df["close"].tail(15)
                delta = closes.diff()
                gain = (delta.where(delta > 0, 0)).mean()
                loss = (-delta.where(delta < 0, 0)).mean()
                if loss != 0:
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs))
                else:
                    rsi = 100
            else:
                return None, None

        origin_ts = latest.get("timestamp")

        if rsi >= RSI_OVERBOUGHT_THRESHOLD:
            return SIGNAL_SHORT, origin_ts

        return None, None

    def _detect_bb_upper_and_rsi_overbought(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect price at BB upper band AND RSI overbought.

        This is a short signal for mean reversion.

        Args:
            df: DataFrame with BB and RSI columns

        Returns:
            (SHORT signal, crossover_origin) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]
        close = latest.get("close", 0)
        rsi = latest.get("rsi_14", latest.get("rsi", None))
        bb_upper = latest.get("bb_upper")

        # Compute BB if not present
        if bb_upper is None and len(df) >= BB_PERIOD:
            closes = df["close"].tail(BB_PERIOD)
            bb_middle = closes.mean()
            bb_std = closes.std()
            bb_upper = bb_middle + (BB_STD * bb_std)

        # Compute RSI if not present
        if rsi is None or np.isnan(rsi):
            if len(df) >= 15:
                closes = df["close"].tail(15)
                delta = closes.diff()
                gain = (delta.where(delta > 0, 0)).mean()
                loss = (-delta.where(delta < 0, 0)).mean()
                if loss != 0:
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs))
                else:
                    rsi = 100
            else:
                return None, None

        if bb_upper is None:
            return None, None

        origin_ts = latest.get("timestamp")

        # Price near or above upper BB AND RSI overbought
        if close >= bb_upper * 0.99 and rsi >= RSI_OVERBOUGHT_THRESHOLD:
            return SIGNAL_SHORT, origin_ts

        return None, None

    def _detect_bb_upper_cross_down(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect price crossing down from BB upper band.

        Args:
            df: DataFrame with BB and price columns

        Returns:
            (SHORT signal, crossover_origin) or (None, None)
        """
        if len(df) < 3:
            return None, None

        latest = df.iloc[-1]
        prev = df.iloc[-2]
        close = latest.get("close", 0)
        prev_close = prev.get("close", 0)

        # Compute BB if not present
        if len(df) >= BB_PERIOD:
            closes = df["close"].tail(BB_PERIOD)
            bb_middle = closes.mean()
            bb_std = closes.std()
            bb_upper = bb_middle + (BB_STD * bb_std)
        else:
            return None, None

        origin_ts = latest.get("timestamp")

        # Previous close above upper BB, current close below
        if prev_close >= bb_upper and close < bb_upper:
            return SIGNAL_SHORT, origin_ts

        return None, None

    def _detect_macd_cross_down_rsi_above_50(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect MACD crossing down while RSI is above 50.

        Args:
            df: DataFrame with MACD and RSI columns

        Returns:
            (SHORT signal, crossover_origin) or (None, None)
        """
        if len(df) < 3:
            return None, None

        latest = df.iloc[-1]
        prev = df.iloc[-2]

        macd = latest.get("macd")
        macd_signal = latest.get("macd_signal")
        prev_macd = prev.get("macd")
        prev_macd_signal = prev.get("macd_signal")
        rsi = latest.get("rsi_14", latest.get("rsi", None))

        # Compute RSI if not present
        if rsi is None or np.isnan(rsi):
            if len(df) >= 15:
                closes = df["close"].tail(15)
                delta = closes.diff()
                gain = (delta.where(delta > 0, 0)).mean()
                loss = (-delta.where(delta < 0, 0)).mean()
                if loss != 0:
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs))
                else:
                    rsi = 100
            else:
                return None, None

        if macd is None or macd_signal is None:
            return None, None
        if prev_macd is None or prev_macd_signal is None:
            return None, None

        origin_ts = latest.get("timestamp")

        # MACD crossed below signal AND RSI > 50
        if prev_macd >= prev_macd_signal and macd < macd_signal and rsi > 50:
            return SIGNAL_SHORT, origin_ts

        return None, None

    # =========================================================================
    # Hybrid V4 Trained Signal Detection Methods
    # =========================================================================

    def _detect_rsi_oversold_long(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect RSI oversold condition for LONG entry.

        Signal triggers when RSI < 30 (oversold), indicating potential reversal.
        Used by Hybrid V4 trained models.

        Args:
            df: DataFrame with RSI indicator

        Returns:
            (LONG signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]
        rsi = latest.get("rsi_14", latest.get("rsi", None))

        # Compute RSI if not present
        if rsi is None or np.isnan(rsi):
            if len(df) >= 15:
                closes = df["close"].tail(15)
                delta = closes.diff()
                gain = (delta.where(delta > 0, 0)).mean()
                loss = (-delta.where(delta < 0, 0)).mean()
                if loss != 0:
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs))
                else:
                    rsi = 100
            else:
                return None, None

        origin_ts = latest.get("timestamp")

        # RSI oversold threshold for LONG entry
        RSI_OVERSOLD_LONG = 30.0
        if rsi <= RSI_OVERSOLD_LONG:
            logger.debug(f"RSI_oversold_long triggered: RSI={rsi:.1f}")
            return SIGNAL_LONG, origin_ts

        return None, None

    def _detect_rsi_bb_confluence_long(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect RSI oversold + Bollinger Band lower confluence for LONG entry.

        Signal: RSI <= 30 (oversold) AND close <= bb_lower * 1.005
        Used by EURGBP RSI_BB_confluence_long signal.
        Trained model: PF=2.35, WR=53.4% (Issue #554)

        Args:
            df: DataFrame with RSI and BB indicators

        Returns:
            (LONG signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]

        # Get RSI
        rsi = latest.get("rsi_14", latest.get("rsi", None))
        if rsi is None or np.isnan(rsi):
            # Compute RSI if not present
            if len(df) >= 15:
                closes = df["close"].tail(15)
                delta = closes.diff()
                gain = (delta.where(delta > 0, 0)).mean()
                loss = (-delta.where(delta < 0, 0)).mean()
                if loss != 0:
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs))
                else:
                    rsi = 100
            else:
                return None, None

        # Get Bollinger Band lower
        bb_lower = latest.get("bb_lower", None)
        close = latest.get("close", None)

        if bb_lower is None or close is None:
            return None, None

        origin_ts = latest.get("timestamp")

        # Confluence conditions
        RSI_OVERSOLD = 30.0
        BB_TOLERANCE = 1.005  # close <= bb_lower * 1.005

        if rsi <= RSI_OVERSOLD and close <= (bb_lower * BB_TOLERANCE):
            logger.debug(
                f"RSI_BB_confluence_long triggered: RSI={rsi:.1f}, "
                f"close={close:.5f}, bb_lower={bb_lower:.5f}"
            )
            return SIGNAL_LONG, origin_ts

        return None, None

    def _detect_rsi_bb_confluence_short(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect RSI overbought + Bollinger Band upper confluence for SHORT entry.

        Signal: RSI >= 70 (overbought) AND close >= bb_upper * 0.995
        Used by USDCHF RSI_BB_confluence_short signal.
        Trained model: PF=4.14, WR=58.8% (Issue #604)

        Args:
            df: DataFrame with RSI and BB indicators

        Returns:
            (SHORT signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]

        # Get RSI
        rsi = latest.get("rsi_14", latest.get("rsi", None))
        if rsi is None or np.isnan(rsi):
            # Compute RSI if not present
            if len(df) >= 15:
                closes = df["close"].tail(15)
                delta = closes.diff()
                gain = (delta.where(delta > 0, 0)).mean()
                loss = (-delta.where(delta < 0, 0)).mean()
                if loss != 0:
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs))
                else:
                    rsi = 100
            else:
                return None, None

        # Get Bollinger Band upper
        bb_upper = latest.get("bb_upper", None)
        close = latest.get("close", None)

        if bb_upper is None or close is None:
            return None, None

        origin_ts = latest.get("timestamp")

        # Confluence conditions
        RSI_OVERBOUGHT = 70.0
        BB_TOLERANCE = 0.995  # close >= bb_upper * 0.995

        if rsi >= RSI_OVERBOUGHT and close >= (bb_upper * BB_TOLERANCE):
            logger.debug(
                f"RSI_BB_confluence_short triggered: RSI={rsi:.1f}, "
                f"close={close:.5f}, bb_upper={bb_upper:.5f}"
            )
            return SIGNAL_SHORT, origin_ts

        return None, None

    def _detect_sma50_200_rsi_stoch_long(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA50/200 trend + RSI + Stochastic filter for LONG entry.

        Signal triggers when:
        - SMA50 > SMA200 (bullish trend)
        - RSI < 50 (not overbought)
        - Stochastic < 50 (room to rise)

        Used by Hybrid V4 trained models.

        Args:
            df: DataFrame with SMA, RSI, Stochastic indicators

        Returns:
            (LONG signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]

        # Get SMA values
        sma_50 = latest.get("sma_50", latest.get("sma50", None))
        sma_200 = latest.get("sma_200", latest.get("sma200", None))

        # Get RSI
        rsi = latest.get("rsi_14", latest.get("rsi", None))

        # Get Stochastic (try multiple column names)
        stoch_k = latest.get("stoch_k", latest.get("stochk", latest.get("slowk", None)))

        # Compute indicators if not present
        if sma_50 is None and len(df) >= 50:
            sma_50 = df["close"].tail(50).mean()
        if sma_200 is None and len(df) >= 200:
            sma_200 = df["close"].tail(200).mean()

        if rsi is None or np.isnan(rsi):
            if len(df) >= 15:
                closes = df["close"].tail(15)
                delta = closes.diff()
                gain = (delta.where(delta > 0, 0)).mean()
                loss = (-delta.where(delta < 0, 0)).mean()
                if loss != 0:
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs))
                else:
                    rsi = 100
            else:
                return None, None

        # If stochastic not available, use RSI as proxy
        if stoch_k is None or np.isnan(stoch_k):
            stoch_k = rsi  # Use RSI as fallback

        # Check if we have required indicators
        if sma_50 is None or sma_200 is None:
            logger.debug("SMA50/200 not available, skipping signal check")
            return None, None

        origin_ts = latest.get("timestamp")

        # Signal conditions:
        # 1. Bullish trend: SMA50 > SMA200
        # 2. RSI not overbought: RSI < 60
        # 3. Stochastic has room: Stoch < 70
        if sma_50 > sma_200 and rsi < 60 and stoch_k < 70:
            logger.debug(
                f"SMA50_200_RSI_Stoch_long triggered: SMA50={sma_50:.5f}, "
                f"SMA200={sma_200:.5f}, RSI={rsi:.1f}, Stoch={stoch_k:.1f}"
            )
            return SIGNAL_LONG, origin_ts

        # Issue #585: Log failure reason with actual vs required values
        logger.debug(
            f"SMA50_200_RSI_Stoch_long NOT triggered: SMA50={sma_50:.5f} (need >SMA200), "
            f"SMA200={sma_200:.5f}, RSI={rsi:.1f} (need <60), Stoch={stoch_k:.1f} (need <70)"
        )
        return None, None

    def _detect_stoch_rsi_long(
        self, df: pd.DataFrame, stoch_thresh: float = 20, rsi_thresh: float = 30
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect combined Stochastic + RSI oversold for LONG entry.

        Signal triggers when both Stochastic and RSI are below thresholds.

        Args:
            df: DataFrame with RSI and Stochastic indicators
            stoch_thresh: Stochastic threshold (default 20)
            rsi_thresh: RSI threshold (default 30)

        Returns:
            (LONG signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]

        # Get RSI
        rsi = latest.get("rsi_14", latest.get("rsi", None))

        # Get Stochastic
        stoch_k = latest.get("stoch_k", latest.get("stochk", latest.get("slowk", None)))

        # Compute RSI if not present
        if rsi is None or np.isnan(rsi):
            if len(df) >= 15:
                closes = df["close"].tail(15)
                delta = closes.diff()
                gain = (delta.where(delta > 0, 0)).mean()
                loss = (-delta.where(delta < 0, 0)).mean()
                if loss != 0:
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs))
                else:
                    rsi = 100
            else:
                return None, None

        # If stochastic not available, skip
        if stoch_k is None or np.isnan(stoch_k):
            return None, None

        origin_ts = latest.get("timestamp")

        # Both indicators must be below thresholds
        if stoch_k <= stoch_thresh and rsi <= rsi_thresh:
            logger.debug(
                f"Stoch_RSI_long triggered: Stoch={stoch_k:.1f}<={stoch_thresh}, "
                f"RSI={rsi:.1f}<={rsi_thresh}"
            )
            return SIGNAL_LONG, origin_ts

        # Issue #585: Log failure reason with actual vs required values
        logger.debug(
            f"Stoch_RSI_long NOT triggered: Stoch={stoch_k:.1f} (need <={stoch_thresh}), "
            f"RSI={rsi:.1f} (need <={rsi_thresh})"
        )
        return None, None

    def _detect_stoch_rsi_short(
        self, df: pd.DataFrame, stoch_thresh: float = 80, rsi_thresh: float = 70
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect combined Stochastic + RSI overbought for SHORT entry.

        Signal triggers when both Stochastic and RSI are above thresholds.

        Args:
            df: DataFrame with RSI and Stochastic indicators
            stoch_thresh: Stochastic threshold (default 80)
            rsi_thresh: RSI threshold (default 70)

        Returns:
            (SHORT signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]

        # Get RSI
        rsi = latest.get("rsi_14", latest.get("rsi", None))

        # Get Stochastic
        stoch_k = latest.get("stoch_k", latest.get("stochk", latest.get("slowk", None)))

        # Compute RSI if not present
        if rsi is None or np.isnan(rsi):
            if len(df) >= 15:
                closes = df["close"].tail(15)
                delta = closes.diff()
                gain = (delta.where(delta > 0, 0)).mean()
                loss = (-delta.where(delta < 0, 0)).mean()
                if loss != 0:
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs))
                else:
                    rsi = 0
            else:
                return None, None

        # If stochastic not available, skip
        if stoch_k is None or np.isnan(stoch_k):
            return None, None

        origin_ts = latest.get("timestamp")

        # Both indicators must be above thresholds (overbought)
        if stoch_k >= stoch_thresh and rsi >= rsi_thresh:
            logger.debug(
                f"Stoch_RSI_short triggered: Stoch={stoch_k:.1f}>={stoch_thresh}, "
                f"RSI={rsi:.1f}>={rsi_thresh}"
            )
            return SIGNAL_SHORT, origin_ts

        # Issue #585: Log failure reason with actual vs required values
        logger.debug(
            f"Stoch_RSI_short NOT triggered: Stoch={stoch_k:.1f} (need >={stoch_thresh}), "
            f"RSI={rsi:.1f} (need >={rsi_thresh})"
        )
        return None, None

    def _detect_macd_stoch_long(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect MACD bullish + Stochastic oversold for LONG entry.

        Signal triggers when:
        - MACD > Signal line (bullish momentum)
        - Stochastic < 30 (oversold condition)

        Args:
            df: DataFrame with MACD and Stochastic indicators

        Returns:
            (LONG signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]

        # Get MACD values
        macd = latest.get("macd", None)
        macd_signal = latest.get("macd_signal", latest.get("macd_signal_line", None))

        # Get Stochastic
        stoch_k = latest.get("stoch_k", latest.get("stochk", latest.get("slowk", None)))

        if macd is None or macd_signal is None or stoch_k is None:
            return None, None

        if np.isnan(macd) or np.isnan(macd_signal) or np.isnan(stoch_k):
            return None, None

        origin_ts = latest.get("timestamp")

        # MACD bullish AND Stochastic oversold
        if macd > macd_signal and stoch_k < 30:
            logger.debug(
                f"MACD_Stoch_long triggered: MACD={macd:.5f}>{macd_signal:.5f}, "
                f"Stoch={stoch_k:.1f}<30"
            )
            return SIGNAL_LONG, origin_ts

        return None, None

    def _detect_macd_stoch_short(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect MACD bearish + Stochastic overbought for SHORT entry.

        Signal triggers when:
        - MACD < Signal line (bearish momentum)
        - Stochastic > 70 (overbought condition)

        Args:
            df: DataFrame with MACD and Stochastic indicators

        Returns:
            (SHORT signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]

        # Get MACD values
        macd = latest.get("macd", None)
        macd_signal = latest.get("macd_signal", latest.get("macd_signal_line", None))

        # Get Stochastic
        stoch_k = latest.get("stoch_k", latest.get("stochk", latest.get("slowk", None)))

        if macd is None or macd_signal is None or stoch_k is None:
            return None, None

        if np.isnan(macd) or np.isnan(macd_signal) or np.isnan(stoch_k):
            return None, None

        origin_ts = latest.get("timestamp")

        # MACD bearish AND Stochastic overbought
        if macd < macd_signal and stoch_k > 70:
            logger.debug(
                f"MACD_Stoch_short triggered: MACD={macd:.5f}<{macd_signal:.5f}, "
                f"Stoch={stoch_k:.1f}>70"
            )
            return SIGNAL_SHORT, origin_ts

        return None, None

    def _detect_triple_momentum_long(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect Triple Momentum signal for LONG entry.

        Signal triggers when all three momentum indicators align:
        - RSI < 40 (oversold)
        - Stochastic < 30 (oversold)
        - MACD histogram positive or turning positive

        Args:
            df: DataFrame with RSI, Stochastic, and MACD indicators

        Returns:
            (LONG signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]

        # Get RSI
        rsi = latest.get("rsi_14", latest.get("rsi", None))

        # Get Stochastic
        stoch_k = latest.get("stoch_k", latest.get("stochk", latest.get("slowk", None)))

        # Get MACD histogram
        macd = latest.get("macd", None)
        macd_signal = latest.get("macd_signal", latest.get("macd_signal_line", None))

        # Compute RSI if needed
        if rsi is None or np.isnan(rsi):
            if len(df) >= 15:
                closes = df["close"].tail(15)
                delta = closes.diff()
                gain = (delta.where(delta > 0, 0)).mean()
                loss = (-delta.where(delta < 0, 0)).mean()
                if loss != 0:
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs))
                else:
                    rsi = 100
            else:
                return None, None

        if stoch_k is None or np.isnan(stoch_k):
            return None, None

        origin_ts = latest.get("timestamp")

        # Calculate MACD histogram if we have MACD values
        macd_hist = 0
        if macd is not None and macd_signal is not None:
            if not (np.isnan(macd) or np.isnan(macd_signal)):
                macd_hist = macd - macd_signal

        # Triple momentum alignment: RSI oversold, Stoch oversold, MACD turning bullish
        if rsi < 40 and stoch_k < 30 and macd_hist > -0.0001:
            logger.debug(
                f"Triple_Momentum_long triggered: RSI={rsi:.1f}<40, "
                f"Stoch={stoch_k:.1f}<30, MACD_hist={macd_hist:.5f}"
            )
            return SIGNAL_LONG, origin_ts

        # Issue #585: Log failure reason with actual vs required values
        logger.debug(
            f"Triple_Momentum_long NOT triggered: RSI={rsi:.1f} (need <40), "
            f"Stoch={stoch_k:.1f} (need <30), MACD_hist={macd_hist:.5f} (need >-0.0001)"
        )
        return None, None

    def _detect_sma20_50_bb_short(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA20/50 bearish + BB upper band for SHORT entry.

        Signal triggers when:
        - SMA20 < SMA50 (bearish trend)
        - Price near or above BB upper band

        Args:
            df: DataFrame with SMA and BB indicators

        Returns:
            (SHORT signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]
        close = latest.get("close", 0)

        # Get SMA values
        sma_20 = latest.get("sma_20", latest.get("sma20", None))
        sma_50 = latest.get("sma_50", latest.get("sma50", None))

        # Get BB values
        bb_upper = latest.get("bb_upper", None)

        # Compute SMA if not present
        if sma_20 is None and len(df) >= 20:
            sma_20 = df["close"].tail(20).mean()
        if sma_50 is None and len(df) >= 50:
            sma_50 = df["close"].tail(50).mean()

        # Compute BB if not present
        if bb_upper is None and len(df) >= BB_PERIOD:
            closes = df["close"].tail(BB_PERIOD)
            bb_middle = closes.mean()
            bb_std = closes.std()
            bb_upper = bb_middle + (BB_STD * bb_std)

        if sma_20 is None or sma_50 is None or bb_upper is None:
            return None, None

        origin_ts = latest.get("timestamp")

        # SMA20 < SMA50 (bearish) AND price at/above upper BB
        if sma_20 < sma_50 and close >= bb_upper * 0.995:
            logger.debug(
                f"SMA20_50_BB_short triggered: SMA20={sma_20:.5f}<SMA50={sma_50:.5f}, "
                f"close={close:.5f}>=BB_upper={bb_upper:.5f}"
            )
            return SIGNAL_SHORT, origin_ts

        # Issue #585: Log failure reason with actual vs required values
        logger.debug(
            f"SMA20_50_BB_short NOT triggered: SMA20={sma_20:.5f} (need <SMA50), "
            f"SMA50={sma_50:.5f}, close={close:.5f} (need >={bb_upper * 0.995:.5f}), "
            f"BB_upper={bb_upper:.5f}"
        )
        return None, None

    def _detect_sma50_200_stoch_bb_short(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA50/200 bearish + Stoch overbought + BB upper for SHORT.

        Signal triggers when:
        - SMA50 < SMA200 (bearish trend)
        - Stochastic > 70 (overbought)
        - Price near BB upper band

        Args:
            df: DataFrame with SMA, Stochastic, and BB indicators

        Returns:
            (SHORT signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]
        close = latest.get("close", 0)

        # Get SMA values
        sma_50 = latest.get("sma_50", latest.get("sma50", None))
        sma_200 = latest.get("sma_200", latest.get("sma200", None))

        # Get Stochastic
        stoch_k = latest.get("stoch_k", latest.get("stochk", latest.get("slowk", None)))

        # Get BB values
        bb_upper = latest.get("bb_upper", None)

        # Compute values if not present
        if sma_50 is None and len(df) >= 50:
            sma_50 = df["close"].tail(50).mean()
        if sma_200 is None and len(df) >= 200:
            sma_200 = df["close"].tail(200).mean()

        if bb_upper is None and len(df) >= BB_PERIOD:
            closes = df["close"].tail(BB_PERIOD)
            bb_middle = closes.mean()
            bb_std = closes.std()
            bb_upper = bb_middle + (BB_STD * bb_std)

        if sma_50 is None or sma_200 is None or stoch_k is None or bb_upper is None:
            return None, None

        if np.isnan(stoch_k):
            return None, None

        origin_ts = latest.get("timestamp")

        # Bearish trend + overbought + at BB upper
        if sma_50 < sma_200 and stoch_k > 70 and close >= bb_upper * 0.99:
            logger.debug(
                f"SMA50_200_Stoch_BB_short triggered: SMA50={sma_50:.5f}<SMA200={sma_200:.5f}, "
                f"Stoch={stoch_k:.1f}>70, close={close:.5f}>=BB={bb_upper:.5f}"
            )
            return SIGNAL_SHORT, origin_ts

        return None, None

    def _detect_sma20_200_bb_long(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA20/200 bullish + BB lower band for LONG entry.

        Signal triggers when:
        - SMA20 > SMA200 (bullish trend)
        - Price near or below BB lower band

        Args:
            df: DataFrame with SMA and BB indicators

        Returns:
            (LONG signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]
        close = latest.get("close", 0)

        # Get SMA values
        sma_20 = latest.get("sma_20", latest.get("sma20", None))
        sma_200 = latest.get("sma_200", latest.get("sma200", None))

        # Get BB values
        bb_lower = latest.get("bb_lower", None)

        # Compute values if not present
        if sma_20 is None and len(df) >= 20:
            sma_20 = df["close"].tail(20).mean()
        if sma_200 is None and len(df) >= 200:
            sma_200 = df["close"].tail(200).mean()

        if bb_lower is None and len(df) >= BB_PERIOD:
            closes = df["close"].tail(BB_PERIOD)
            bb_middle = closes.mean()
            bb_std = closes.std()
            bb_lower = bb_middle - (BB_STD * bb_std)

        if sma_20 is None or sma_200 is None or bb_lower is None:
            return None, None

        origin_ts = latest.get("timestamp")

        # Bullish trend + price at/below lower BB
        if sma_20 > sma_200 and close <= bb_lower * 1.005:
            logger.debug(
                f"SMA20_200_BB_long triggered: SMA20={sma_20:.5f}>SMA200={sma_200:.5f}, "
                f"close={close:.5f}<=BB_lower={bb_lower:.5f}"
            )
            return SIGNAL_LONG, origin_ts

        return None, None

    def _detect_sma20_50_macd_long(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA20/50 bullish + MACD bullish for LONG entry.

        Signal triggers when:
        - SMA20 > SMA50 (bullish trend)
        - MACD > Signal line (bullish momentum)

        Args:
            df: DataFrame with SMA and MACD indicators

        Returns:
            (LONG signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]

        # Get SMA values
        sma_20 = latest.get("sma_20", latest.get("sma20", None))
        sma_50 = latest.get("sma_50", latest.get("sma50", None))

        # Get MACD values
        macd = latest.get("macd", None)
        macd_signal = latest.get("macd_signal", latest.get("macd_signal_line", None))

        # Compute SMA if not present
        if sma_20 is None and len(df) >= 20:
            sma_20 = df["close"].tail(20).mean()
        if sma_50 is None and len(df) >= 50:
            sma_50 = df["close"].tail(50).mean()

        if sma_20 is None or sma_50 is None:
            return None, None

        if macd is None or macd_signal is None:
            return None, None

        if np.isnan(macd) or np.isnan(macd_signal):
            return None, None

        origin_ts = latest.get("timestamp")

        # Bullish SMA + bullish MACD
        if sma_20 > sma_50 and macd > macd_signal:
            logger.debug(
                f"SMA20_50_MACD_long triggered: SMA20={sma_20:.5f}>SMA50={sma_50:.5f}, "
                f"MACD={macd:.5f}>{macd_signal:.5f}"
            )
            return SIGNAL_LONG, origin_ts

        return None, None

    def _detect_sma20_50_rsi_stoch_bb_short(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect complex multi-indicator SHORT signal.

        Signal triggers when:
        - SMA20 < SMA50 (bearish trend)
        - RSI > 60 (not oversold)
        - Stochastic > 70 (overbought)
        - Price near BB upper band

        Args:
            df: DataFrame with multiple indicators

        Returns:
            (SHORT signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]
        close = latest.get("close", 0)

        # Get all indicator values
        sma_20 = latest.get("sma_20", latest.get("sma20", None))
        sma_50 = latest.get("sma_50", latest.get("sma50", None))
        rsi = latest.get("rsi_14", latest.get("rsi", None))
        stoch_k = latest.get("stoch_k", latest.get("stochk", latest.get("slowk", None)))
        bb_upper = latest.get("bb_upper", None)

        # Compute values if not present
        if sma_20 is None and len(df) >= 20:
            sma_20 = df["close"].tail(20).mean()
        if sma_50 is None and len(df) >= 50:
            sma_50 = df["close"].tail(50).mean()

        if rsi is None or np.isnan(rsi):
            if len(df) >= 15:
                closes = df["close"].tail(15)
                delta = closes.diff()
                gain = (delta.where(delta > 0, 0)).mean()
                loss = (-delta.where(delta < 0, 0)).mean()
                if loss != 0:
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs))
                else:
                    rsi = 0

        if bb_upper is None and len(df) >= BB_PERIOD:
            closes = df["close"].tail(BB_PERIOD)
            bb_middle = closes.mean()
            bb_std = closes.std()
            bb_upper = bb_middle + (BB_STD * bb_std)

        if sma_20 is None or sma_50 is None or rsi is None or stoch_k is None or bb_upper is None:
            return None, None

        if np.isnan(stoch_k):
            return None, None

        origin_ts = latest.get("timestamp")

        # All conditions for SHORT
        if sma_20 < sma_50 and rsi > 60 and stoch_k > 70 and close >= bb_upper * 0.995:
            logger.debug(
                f"SMA20_50_RSI_Stoch_BB_short triggered: SMA bearish, "
                f"RSI={rsi:.1f}>60, Stoch={stoch_k:.1f}>70, at BB_upper"
            )
            return SIGNAL_SHORT, origin_ts

        return None, None

    def _detect_sma20_200_stoch_short(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA20/200 bearish + Stochastic overbought for SHORT.

        Signal triggers when:
        - SMA20 < SMA200 (bearish trend)
        - Stochastic > 75 (overbought)

        Args:
            df: DataFrame with SMA and Stochastic indicators

        Returns:
            (SHORT signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]

        # Get SMA values
        sma_20 = latest.get("sma_20", latest.get("sma20", None))
        sma_200 = latest.get("sma_200", latest.get("sma200", None))

        # Get Stochastic
        stoch_k = latest.get("stoch_k", latest.get("stochk", latest.get("slowk", None)))

        # Compute values if not present
        if sma_20 is None and len(df) >= 20:
            sma_20 = df["close"].tail(20).mean()
        if sma_200 is None and len(df) >= 200:
            sma_200 = df["close"].tail(200).mean()

        if sma_20 is None or sma_200 is None or stoch_k is None:
            return None, None

        if np.isnan(stoch_k):
            return None, None

        origin_ts = latest.get("timestamp")

        # Bearish trend + overbought stochastic
        if sma_20 < sma_200 and stoch_k > 75:
            logger.debug(
                f"SMA20_200_Stoch_short triggered: SMA20={sma_20:.5f}<SMA200={sma_200:.5f}, "
                f"Stoch={stoch_k:.1f}>75"
            )
            return SIGNAL_SHORT, origin_ts

        return None, None

    def _detect_macd_cross_long(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect MACD crossing above signal line for LONG entry.

        Signal triggers when:
        - MACD crosses above signal line (bullish crossover)

        Args:
            df: DataFrame with MACD indicators

        Returns:
            (LONG signal, origin_timestamp) or (None, None)
        """
        if len(df) < 3:
            return None, None

        latest = df.iloc[-1]
        prev = df.iloc[-2]

        # Get MACD values
        macd = latest.get("macd", None)
        macd_signal = latest.get("macd_signal", latest.get("macd_signal_line", None))
        prev_macd = prev.get("macd", None)
        prev_macd_signal = prev.get("macd_signal", prev.get("macd_signal_line", None))

        if macd is None or macd_signal is None or prev_macd is None or prev_macd_signal is None:
            return None, None

        if np.isnan(macd) or np.isnan(macd_signal) or np.isnan(prev_macd) or np.isnan(prev_macd_signal):
            return None, None

        origin_ts = latest.get("timestamp")

        # MACD crossed above signal line
        if prev_macd <= prev_macd_signal and macd > macd_signal:
            logger.debug(
                f"MACD_cross_long triggered: prev_MACD={prev_macd:.5f}<=prev_sig={prev_macd_signal:.5f}, "
                f"MACD={macd:.5f}>{macd_signal:.5f}"
            )
            return SIGNAL_LONG, origin_ts

        return None, None

    def _detect_sma20_50_rsi_long(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA20/50 bullish + RSI oversold for LONG entry.

        Signal triggers when:
        - SMA20 > SMA50 (bullish trend)
        - RSI < 40 (oversold, room to rise)

        Args:
            df: DataFrame with SMA and RSI indicators

        Returns:
            (LONG signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]

        # Get SMA values
        sma_20 = latest.get("sma_20", latest.get("sma20", None))
        sma_50 = latest.get("sma_50", latest.get("sma50", None))

        # Get RSI
        rsi = latest.get("rsi_14", latest.get("rsi", None))

        # Compute values if not present
        if sma_20 is None and len(df) >= 20:
            sma_20 = df["close"].tail(20).mean()
        if sma_50 is None and len(df) >= 50:
            sma_50 = df["close"].tail(50).mean()

        if rsi is None or np.isnan(rsi):
            if len(df) >= 15:
                closes = df["close"].tail(15)
                delta = closes.diff()
                gain = (delta.where(delta > 0, 0)).mean()
                loss = (-delta.where(delta < 0, 0)).mean()
                if loss != 0:
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs))
                else:
                    rsi = 100

        if sma_20 is None or sma_50 is None or rsi is None:
            return None, None

        origin_ts = latest.get("timestamp")

        # Bullish trend + RSI oversold
        if sma_20 > sma_50 and rsi < 40:
            logger.debug(
                f"SMA20_50_RSI_long triggered: SMA20={sma_20:.5f}>SMA50={sma_50:.5f}, "
                f"RSI={rsi:.1f}<40"
            )
            return SIGNAL_LONG, origin_ts

        return None, None

    def _detect_ema_rsi_long(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect EMA trend + RSI oversold for LONG entry.

        Signal triggers when:
        - EMA12 > EMA26 (bullish trend)
        - RSI < 40 (oversold, room to rise)

        Issue #585: Added missing signal handler.

        Args:
            df: DataFrame with EMA and RSI indicators

        Returns:
            (LONG signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]

        # Get EMA values
        ema_12 = latest.get("ema_12", latest.get("ema12", None))
        ema_26 = latest.get("ema_26", latest.get("ema26", None))

        # Get RSI
        rsi = latest.get("rsi_14", latest.get("rsi", None))

        # Compute RSI if not present
        if rsi is None or np.isnan(rsi):
            if len(df) >= 15:
                closes = df["close"].tail(15)
                delta = closes.diff()
                gain = (delta.where(delta > 0, 0)).mean()
                loss = (-delta.where(delta < 0, 0)).mean()
                if loss != 0:
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs))
                else:
                    rsi = 100
            else:
                return None, None

        if ema_12 is None or ema_26 is None or rsi is None:
            return None, None

        origin_ts = latest.get("timestamp")

        # Bullish EMA trend + RSI oversold
        if ema_12 > ema_26 and rsi < 40:
            logger.debug(
                f"EMA_RSI_long triggered: EMA12={ema_12:.5f}>EMA26={ema_26:.5f}, "
                f"RSI={rsi:.1f}<40"
            )
            return SIGNAL_LONG, origin_ts

        return None, None

    def _detect_sma20_200_rsi_long(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA20/200 trend + RSI oversold for LONG entry.

        Signal triggers when:
        - SMA20 > SMA200 (bullish trend)
        - RSI < 40 (oversold, room to rise)

        Issue #585: Added missing signal handler.

        Args:
            df: DataFrame with SMA and RSI indicators

        Returns:
            (LONG signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]

        # Get SMA values
        sma_20 = latest.get("sma_20", latest.get("sma20", None))
        sma_200 = latest.get("sma_200", latest.get("sma200", None))

        # Get RSI
        rsi = latest.get("rsi_14", latest.get("rsi", None))

        # Compute values if not present
        if sma_20 is None and len(df) >= 20:
            sma_20 = df["close"].tail(20).mean()
        if sma_200 is None and len(df) >= 200:
            sma_200 = df["close"].tail(200).mean()

        if rsi is None or np.isnan(rsi):
            if len(df) >= 15:
                closes = df["close"].tail(15)
                delta = closes.diff()
                gain = (delta.where(delta > 0, 0)).mean()
                loss = (-delta.where(delta < 0, 0)).mean()
                if loss != 0:
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs))
                else:
                    rsi = 100

        if sma_20 is None or sma_200 is None or rsi is None:
            return None, None

        origin_ts = latest.get("timestamp")

        # Bullish trend + RSI oversold
        if sma_20 > sma_200 and rsi < 40:
            logger.debug(
                f"SMA20_200_RSI_long triggered: SMA20={sma_20:.5f}>SMA200={sma_200:.5f}, "
                f"RSI={rsi:.1f}<40"
            )
            return SIGNAL_LONG, origin_ts

        return None, None

    def _detect_sma50_200_rsi_stoch_bb_long(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA50/200 trend + momentum + BB confluence for LONG entry.

        Signal triggers when:
        - SMA50 > SMA200 (bullish trend)
        - RSI < 60 (not overbought)
        - Stoch < 70 (room to rise)
        - close <= bb_lower * 1.005 (price near lower BB)

        Issue #585: Added missing signal handler.

        Args:
            df: DataFrame with SMA, RSI, Stochastic, and BB indicators

        Returns:
            (LONG signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]
        close = latest.get("close", 0)

        # Get SMA values
        sma_50 = latest.get("sma_50", latest.get("sma50", None))
        sma_200 = latest.get("sma_200", latest.get("sma200", None))

        # Get RSI
        rsi = latest.get("rsi_14", latest.get("rsi", None))

        # Get Stochastic
        stoch_k = latest.get("stoch_k", latest.get("stochk", latest.get("slowk", None)))

        # Get BB values
        bb_lower = latest.get("bb_lower", None)

        # Compute values if not present
        if sma_50 is None and len(df) >= 50:
            sma_50 = df["close"].tail(50).mean()
        if sma_200 is None and len(df) >= 200:
            sma_200 = df["close"].tail(200).mean()

        if rsi is None or np.isnan(rsi):
            if len(df) >= 15:
                closes = df["close"].tail(15)
                delta = closes.diff()
                gain = (delta.where(delta > 0, 0)).mean()
                loss = (-delta.where(delta < 0, 0)).mean()
                if loss != 0:
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs))
                else:
                    rsi = 100
            else:
                return None, None

        if stoch_k is None or np.isnan(stoch_k):
            stoch_k = rsi  # Use RSI as fallback

        if bb_lower is None and len(df) >= BB_PERIOD:
            closes = df["close"].tail(BB_PERIOD)
            bb_middle = closes.mean()
            bb_std = closes.std()
            bb_lower = bb_middle - (BB_STD * bb_std)

        if sma_50 is None or sma_200 is None or rsi is None or bb_lower is None:
            return None, None

        origin_ts = latest.get("timestamp")

        # All 4 conditions: bullish trend + momentum room + price at lower BB
        if sma_50 > sma_200 and rsi < 60 and stoch_k < 70 and close <= bb_lower * 1.005:
            logger.debug(
                f"SMA50_200_RSI_Stoch_BB_long triggered: SMA50={sma_50:.5f}>SMA200={sma_200:.5f}, "
                f"RSI={rsi:.1f}<60, Stoch={stoch_k:.1f}<70, close={close:.5f}<=BB_lower={bb_lower:.5f}"
            )
            return SIGNAL_LONG, origin_ts

        return None, None

    def _detect_stoch_k_oversold_long(
        self, df: pd.DataFrame, stoch_thresh: float = 25
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect Stochastic %K oversold condition for LONG entry.

        Signal triggers when Stochastic %K is below threshold (oversold).
        Issue #560: Added for EURUSD signals.

        Args:
            df: DataFrame with Stochastic indicators
            stoch_thresh: Stochastic %K threshold (default 25)

        Returns:
            (LONG signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]

        # Get Stochastic %K
        stoch_k = latest.get("stoch_k", latest.get("stochk", latest.get("slowk", None)))

        if stoch_k is None or np.isnan(stoch_k):
            return None, None

        origin_ts = latest.get("timestamp")

        # Stochastic oversold
        if stoch_k < stoch_thresh:
            logger.debug(
                f"Stoch_K_oversold_long_{int(stoch_thresh)} triggered: Stoch_K={stoch_k:.1f}<{stoch_thresh}"
            )
            return SIGNAL_LONG, origin_ts

        return None, None

    def _detect_sma20_50_bb_long(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA20/50 bullish + BB lower band for LONG entry.

        Signal triggers when:
        - SMA20 > SMA50 (bullish trend)
        - Price near or below BB lower band

        Issue #560: Added for EURUSD signals.

        Args:
            df: DataFrame with SMA and BB indicators

        Returns:
            (LONG signal, origin_timestamp) or (None, None)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]
        close = latest.get("close", 0)

        # Get SMA values
        sma_20 = latest.get("sma_20", latest.get("sma20", None))
        sma_50 = latest.get("sma_50", latest.get("sma50", None))

        # Get BB values
        bb_lower = latest.get("bb_lower", None)

        # Compute SMA if not present
        if sma_20 is None and len(df) >= 20:
            sma_20 = df["close"].tail(20).mean()
        if sma_50 is None and len(df) >= 50:
            sma_50 = df["close"].tail(50).mean()

        # Compute BB if not present
        if bb_lower is None and len(df) >= BB_PERIOD:
            closes = df["close"].tail(BB_PERIOD)
            bb_middle = closes.mean()
            bb_std = closes.std()
            bb_lower = bb_middle - (BB_STD * bb_std)

        if sma_20 is None or sma_50 is None or bb_lower is None:
            return None, None

        origin_ts = latest.get("timestamp")

        # Bullish trend + price at BB lower band
        if sma_20 > sma_50 and close <= bb_lower * 1.005:
            logger.debug(
                f"SMA20_50_BB_long triggered: SMA20={sma_20:.5f}>SMA50={sma_50:.5f}, "
                f"close={close:.5f}<=BB_lower={bb_lower:.5f}"
            )
            return SIGNAL_LONG, origin_ts

        return None, None

    def _detect_sma20_200_rsi_stoch_long(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA20/200 bullish + RSI oversold + Stochastic oversold for LONG.

        Signal triggers when:
        - SMA20 > SMA200 (bullish trend)
        - RSI < 40 (oversold)
        - Stochastic < 30 (oversold)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]

        sma_20 = latest.get("sma_20", latest.get("sma20", None))
        sma_200 = latest.get("sma_200", latest.get("sma200", None))
        rsi = latest.get("rsi_14", latest.get("rsi", None))
        stoch_k = latest.get("stoch_k", latest.get("stochk", latest.get("slowk", None)))

        if sma_20 is None and len(df) >= 20:
            sma_20 = df["close"].tail(20).mean()
        if sma_200 is None and len(df) >= 200:
            sma_200 = df["close"].tail(200).mean()

        if sma_20 is None or sma_200 is None or rsi is None or stoch_k is None:
            return None, None
        if np.isnan(stoch_k) or np.isnan(rsi):
            return None, None

        origin_ts = latest.get("timestamp")

        if sma_20 > sma_200 and rsi < 40 and stoch_k < 30:
            logger.debug(f"SMA20_200_RSI_Stoch_long triggered: bullish, RSI={rsi:.1f}<40, Stoch={stoch_k:.1f}<30")
            return SIGNAL_LONG, origin_ts

        return None, None

    def _detect_sma20_200_rsi_stoch_short(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA20/200 bearish + RSI overbought + Stochastic overbought for SHORT.

        Signal triggers when:
        - SMA20 < SMA200 (bearish trend)
        - RSI > 60 (overbought)
        - Stochastic > 70 (overbought)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]

        sma_20 = latest.get("sma_20", latest.get("sma20", None))
        sma_200 = latest.get("sma_200", latest.get("sma200", None))
        rsi = latest.get("rsi_14", latest.get("rsi", None))
        stoch_k = latest.get("stoch_k", latest.get("stochk", latest.get("slowk", None)))

        if sma_20 is None and len(df) >= 20:
            sma_20 = df["close"].tail(20).mean()
        if sma_200 is None and len(df) >= 200:
            sma_200 = df["close"].tail(200).mean()

        if sma_20 is None or sma_200 is None or rsi is None or stoch_k is None:
            return None, None
        if np.isnan(stoch_k) or np.isnan(rsi):
            return None, None

        origin_ts = latest.get("timestamp")

        if sma_20 < sma_200 and rsi > 60 and stoch_k > 70:
            logger.debug(f"SMA20_200_RSI_Stoch_short triggered: bearish, RSI={rsi:.1f}>60, Stoch={stoch_k:.1f}>70")
            return SIGNAL_SHORT, origin_ts

        return None, None

    def _detect_sma20_200_stoch_bb_short(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA20/200 bearish + Stochastic overbought + BB upper for SHORT.

        Signal triggers when:
        - SMA20 < SMA200 (bearish trend)
        - Stochastic > 70 (overbought)
        - Price near BB upper band
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]
        close = latest.get("close", 0)

        sma_20 = latest.get("sma_20", latest.get("sma20", None))
        sma_200 = latest.get("sma_200", latest.get("sma200", None))
        stoch_k = latest.get("stoch_k", latest.get("stochk", latest.get("slowk", None)))
        bb_upper = latest.get("bb_upper", None)

        if sma_20 is None and len(df) >= 20:
            sma_20 = df["close"].tail(20).mean()
        if sma_200 is None and len(df) >= 200:
            sma_200 = df["close"].tail(200).mean()
        if bb_upper is None and len(df) >= BB_PERIOD:
            closes = df["close"].tail(BB_PERIOD)
            bb_middle = closes.mean()
            bb_std = closes.std()
            bb_upper = bb_middle + (BB_STD * bb_std)

        if sma_20 is None or sma_200 is None or stoch_k is None or bb_upper is None:
            return None, None
        if np.isnan(stoch_k):
            return None, None

        origin_ts = latest.get("timestamp")

        if sma_20 < sma_200 and stoch_k > 70 and close >= bb_upper * 0.995:
            logger.debug(f"SMA20_200_Stoch_BB_short triggered: bearish, Stoch={stoch_k:.1f}>70, at BB_upper")
            return SIGNAL_SHORT, origin_ts

        return None, None

    def _detect_sma20_50_stoch_bb_short(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA20/50 bearish + Stochastic overbought + BB upper for SHORT.

        Signal triggers when:
        - SMA20 < SMA50 (bearish trend)
        - Stochastic > 70 (overbought)
        - Price near BB upper band
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]
        close = latest.get("close", 0)

        sma_20 = latest.get("sma_20", latest.get("sma20", None))
        sma_50 = latest.get("sma_50", latest.get("sma50", None))
        stoch_k = latest.get("stoch_k", latest.get("stochk", latest.get("slowk", None)))
        bb_upper = latest.get("bb_upper", None)

        if sma_20 is None and len(df) >= 20:
            sma_20 = df["close"].tail(20).mean()
        if sma_50 is None and len(df) >= 50:
            sma_50 = df["close"].tail(50).mean()
        if bb_upper is None and len(df) >= BB_PERIOD:
            closes = df["close"].tail(BB_PERIOD)
            bb_middle = closes.mean()
            bb_std = closes.std()
            bb_upper = bb_middle + (BB_STD * bb_std)

        if sma_20 is None or sma_50 is None or stoch_k is None or bb_upper is None:
            return None, None
        if np.isnan(stoch_k):
            return None, None

        origin_ts = latest.get("timestamp")

        if sma_20 < sma_50 and stoch_k > 70 and close >= bb_upper * 0.995:
            logger.debug(f"SMA20_50_Stoch_BB_short triggered: bearish, Stoch={stoch_k:.1f}>70, at BB_upper")
            return SIGNAL_SHORT, origin_ts

        return None, None

    def _detect_sma50_200_rsi_stoch_bb_short(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA50/200 bearish + RSI + Stoch overbought + BB upper for SHORT.

        Signal triggers when:
        - SMA50 < SMA200 (bearish trend)
        - RSI > 60 (overbought)
        - Stochastic > 70 (overbought)
        - Price near BB upper band
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]
        close = latest.get("close", 0)

        sma_50 = latest.get("sma_50", latest.get("sma50", None))
        sma_200 = latest.get("sma_200", latest.get("sma200", None))
        rsi = latest.get("rsi_14", latest.get("rsi", None))
        stoch_k = latest.get("stoch_k", latest.get("stochk", latest.get("slowk", None)))
        bb_upper = latest.get("bb_upper", None)

        if sma_50 is None and len(df) >= 50:
            sma_50 = df["close"].tail(50).mean()
        if sma_200 is None and len(df) >= 200:
            sma_200 = df["close"].tail(200).mean()
        if bb_upper is None and len(df) >= BB_PERIOD:
            closes = df["close"].tail(BB_PERIOD)
            bb_middle = closes.mean()
            bb_std = closes.std()
            bb_upper = bb_middle + (BB_STD * bb_std)

        if sma_50 is None or sma_200 is None or rsi is None or stoch_k is None or bb_upper is None:
            return None, None
        if np.isnan(stoch_k) or np.isnan(rsi):
            return None, None

        origin_ts = latest.get("timestamp")

        if sma_50 < sma_200 and rsi > 60 and stoch_k > 70 and close >= bb_upper * 0.995:
            logger.debug(f"SMA50_200_RSI_Stoch_BB_short triggered: bearish, RSI={rsi:.1f}>60, Stoch={stoch_k:.1f}>70, at BB_upper")
            return SIGNAL_SHORT, origin_ts

        return None, None

    def _detect_sma50_200_rsi_stoch_short(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA50/200 bearish + RSI overbought + Stochastic overbought for SHORT.

        Signal triggers when:
        - SMA50 < SMA200 (bearish trend)
        - RSI > 60 (overbought)
        - Stochastic > 70 (overbought)
        """
        if len(df) < 2:
            return None, None

        latest = df.iloc[-1]

        sma_50 = latest.get("sma_50", latest.get("sma50", None))
        sma_200 = latest.get("sma_200", latest.get("sma200", None))
        rsi = latest.get("rsi_14", latest.get("rsi", None))
        stoch_k = latest.get("stoch_k", latest.get("stochk", latest.get("slowk", None)))

        if sma_50 is None and len(df) >= 50:
            sma_50 = df["close"].tail(50).mean()
        if sma_200 is None and len(df) >= 200:
            sma_200 = df["close"].tail(200).mean()

        if sma_50 is None or sma_200 is None or rsi is None or stoch_k is None:
            return None, None
        if np.isnan(stoch_k) or np.isnan(rsi):
            return None, None

        origin_ts = latest.get("timestamp")

        if sma_50 < sma_200 and rsi > 60 and stoch_k > 70:
            logger.debug(f"SMA50_200_RSI_Stoch_short triggered: bearish, RSI={rsi:.1f}>60, Stoch={stoch_k:.1f}>70")
            return SIGNAL_SHORT, origin_ts

        return None, None

    def _detect_sma_20_50_cross_short(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA20 crossing below SMA50 for SHORT entry.

        Signal triggers when:
        - SMA20 crosses below SMA50 (death cross)
        """
        if len(df) < 3:
            return None, None

        latest = df.iloc[-1]
        prev = df.iloc[-2]

        sma_20 = latest.get("sma_20", latest.get("sma20", None))
        sma_50 = latest.get("sma_50", latest.get("sma50", None))
        prev_sma_20 = prev.get("sma_20", prev.get("sma20", None))
        prev_sma_50 = prev.get("sma_50", prev.get("sma50", None))

        if sma_20 is None and len(df) >= 20:
            sma_20 = df["close"].tail(20).mean()
        if sma_50 is None and len(df) >= 50:
            sma_50 = df["close"].tail(50).mean()

        if sma_20 is None or sma_50 is None or prev_sma_20 is None or prev_sma_50 is None:
            return None, None

        origin_ts = latest.get("timestamp")

        # Death cross: SMA20 was above SMA50, now below
        if prev_sma_20 >= prev_sma_50 and sma_20 < sma_50:
            logger.debug(f"SMA_20_50_cross_short triggered: death cross, SMA20={sma_20:.5f}<SMA50={sma_50:.5f}")
            return SIGNAL_SHORT, origin_ts

        return None, None

    def _get_signal_source(self, symbol: str, signal: str) -> str:
        """Generate signal source string for audit.

        Args:
            symbol: Trading symbol
            signal: Signal direction ("LONG" or "SHORT")

        Returns:
            Signal source string
        """
        if self.timeframe == "D1":
            direction = "up" if signal == SIGNAL_LONG else "down"
            return f"D1_SMA20_cross_SMA50_{direction}"

        # H4 mode - use signal config name directly
        config = self.signal_config.get(symbol, {})
        signal_type = config.get("signal", "EMA12_cross_EMA26")

        # Hybrid V4 trained signals already include direction in name
        if signal_type in (
            "RSI_oversold_long",
            "SMA50_200_RSI_Stoch_long",
            "Stoch_RSI_long_15_25",
            "Stoch_RSI_long_15_30",
            "Stoch_RSI_long_15_35",
            "Stoch_RSI_long_20_30",
            "Stoch_RSI_long_20_35",
        ):
            return signal_type

        # Legacy signal types need direction suffix
        direction = "up" if signal == SIGNAL_LONG else "down"
        if signal_type == "EMA12_cross_EMA26":
            return f"H4_EMA12_cross_EMA26_{direction}"
        elif signal_type == "ATR_breakout":
            return f"H4_ATR_breakout_{direction}"
        else:
            return f"H4_{signal_type}"

    def _compute_crossover_signals(self, df: pd.DataFrame) -> pd.DataFrame:
        """Compute SMA crossover signals on D1 data.

        Args:
            df: DataFrame with sma_20 and sma_50 columns

        Returns:
            DataFrame with crossover columns added
        """
        if len(df) < 2:
            return df

        # SMA20 vs SMA50 trend
        df["sma20_above_sma50"] = df["sma_20"] > df["sma_50"]

        # Detect crossovers (change from previous bar)
        df["sma_cross_up"] = (df["sma20_above_sma50"] == True) & (
            df["sma20_above_sma50"].shift(1) == False
        )
        df["sma_cross_down"] = (df["sma20_above_sma50"] == False) & (
            df["sma20_above_sma50"].shift(1) == True
        )

        # Look for recent crossovers (within lookback period)
        df["recent_cross_up"] = (
            df["sma_cross_up"]
            .rolling(window=self.cross_lookback, min_periods=1)
            .max()
            .fillna(0)
            .astype(bool)
        )

        df["recent_cross_down"] = (
            df["sma_cross_down"]
            .rolling(window=self.cross_lookback, min_periods=1)
            .max()
            .fillna(0)
            .astype(bool)
        )

        # EMA trend for confirmation
        df["ema12_above_ema26"] = df["ema_12"] > df["ema_26"]

        return df

    def _detect_crossover(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[str], Optional[datetime]]:
        """Detect SMA crossover signal and find origin.

        Args:
            df: DataFrame with crossover columns

        Returns:
            (signal, crossover_origin) or (None, None)
        """
        if len(df) == 0:
            return None, None

        latest = df.iloc[-1]

        signal = None
        if latest.get("recent_cross_up", False):
            signal = SIGNAL_LONG
        elif latest.get("recent_cross_down", False):
            signal = SIGNAL_SHORT

        if signal is None:
            return None, None

        # Find the crossover origin
        cross_col = "sma_cross_up" if signal == SIGNAL_LONG else "sma_cross_down"
        lookback = df.tail(self.cross_lookback)

        cross_mask = lookback[cross_col] == True
        if cross_mask.any():
            origin_row = lookback[cross_mask].iloc[0]
            origin_ts = origin_row["timestamp"]
        else:
            origin_ts = lookback.iloc[0]["timestamp"]

        return signal, origin_ts

    def _is_crossover_locked(self, symbol: str, crossover_origin: datetime) -> bool:
        """Check if crossover is already locked.

        Args:
            symbol: Trading symbol
            crossover_origin: Crossover timestamp

        Returns:
            True if locked, False otherwise
        """
        last_traded = self._last_traded_crossover.get(symbol)
        if last_traded is None:
            return False

        # Normalize timestamps for comparison
        if isinstance(crossover_origin, pd.Timestamp):
            crossover_origin = crossover_origin.to_pydatetime()
        if crossover_origin.tzinfo is None:
            crossover_origin = crossover_origin.replace(tzinfo=timezone.utc)
        if last_traded.tzinfo is None:
            last_traded = last_traded.replace(tzinfo=timezone.utc)

        return crossover_origin == last_traded

    def _calculate_confidence(self, df: pd.DataFrame) -> float:
        """Calculate signal confidence based on additional factors.

        Args:
            df: DataFrame with indicator data

        Returns:
            Confidence score (0.0 to 1.0)
        """
        if len(df) == 0:
            return 0.5

        latest = df.iloc[-1]
        confidence = 0.6  # Base confidence for D1 crossover

        # EMA alignment bonus
        sma_bullish = latest.get("sma20_above_sma50", False)
        ema_bullish = latest.get("ema12_above_ema26", False)
        if sma_bullish == ema_bullish:
            confidence += 0.1  # Trend alignment

        # RSI confirmation
        rsi = latest.get("rsi_14", 50)
        if rsi is not None:
            if sma_bullish and 40 < rsi < 70:
                confidence += 0.1  # RSI supports bullish
            elif not sma_bullish and 30 < rsi < 60:
                confidence += 0.1  # RSI supports bearish

        return min(confidence, 1.0)

    def check_crossover_status(
        self, symbol: str, signal_type: str, direction: str, timeframe: str
    ) -> Tuple[bool, bool]:
        """Check if a signal has a fresh crossover and if it's locked.

        Read-only check used by SignalPreviewEvaluator to determine status.
        Does NOT modify any state or lock signals.

        Args:
            symbol: Trading symbol (e.g., "EURUSD")
            signal_type: Signal name (e.g., "SMA50_200_RSI_Stoch_long")
            direction: "long" or "short"
            timeframe: Signal timeframe (e.g., "H1")

        Returns:
            Tuple of (has_fresh_crossover, is_locked)
        """
        symbol = symbol.upper()
        lock_key = f"{symbol}:{signal_type}"

        try:
            data = self._fetch_timeframe_data(symbol, timeframe)
            if data is None or len(data) < self.cross_lookback + 1:
                return False, False

            signal, crossover_origin = self._detect_signal_for_config(
                data, signal_type, direction.upper()
            )

            if signal is None or crossover_origin is None:
                return False, False

            is_locked = self._is_signal_locked(lock_key, crossover_origin)
            return True, is_locked

        except Exception as e:
            logger.debug(f"check_crossover_status failed for {lock_key}: {e}")
            return False, False

    def clear_signal_locks(self) -> None:
        """Clear all signal locks (use for testing or reset)."""
        self._last_traded_crossover.clear()
        logger.info("Cleared all signal locks")

    def get_status(self) -> Dict[str, Any]:
        """Get evaluator status for monitoring.

        Returns:
            Status dictionary
        """
        return {
            "evaluator_type": "hybrid",
            "symbols": self.symbols,
            "timeframe": self.timeframe,
            "signal_config": self.signal_config,
            "cross_lookback": self.cross_lookback,
            "locked_crossovers": {
                sym: str(ts) for sym, ts in self._last_traded_crossover.items()
            },
            "cache_symbols": list(self._d1_cache.keys()),
            "h4_cache_symbols": list(self._h4_cache.keys()),
        }
